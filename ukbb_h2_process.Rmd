---
title: "Defining UKB Round 2 heritable phenotypes"
date: "Last updated `r format(Sys.Date())`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
# devtools::install_github("ropensci/plotly")
require(plotly)
require(DT)
require(crosstalk)
require(crosstool)
require(Rmpfr)

plotly_colors <- c(
    '#1f77b4',  # muted blue
    '#ff7f0e',  # safety orange
    '#2ca02c',  # cooked asparagus green
    '#d62728',  # brick red
    '#9467bd',  # muted purple
    '#8c564b',  # chestnut brown
    '#e377c2',  # raspberry yogurt pink
    '#7f7f7f',  # middle gray
    '#bcbd22',  # curry yellow-green
    '#17becf'   # blue-teal
) # https://stackoverflow.com/questions/40673490/how-to-get-plotly-js-default-colors-list
```

<style type="text/css">
div.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r data_load, include=FALSE, cache=TRUE}
# load full h2 results
dat_load <- read.delim("ukb31063.h2.baseline1-1.gwas_v2.full_results.14Aug2019.tsv.gz",sep = '\t', quote = "", header=T, stringsAsFactors = F)

# for reverse matching the raw vs irnt codes
dat_load$phen_stem <- as.character(dat_load$phenotype)
dat_load$phen_stem[is.na(dat_load$n_cases)] <- as.character(sapply(dat_load$phenotype[is.na(dat_load$n_cases)],function(a) strsplit(a, "_")[[1]][1]))

# convenience additions
dat_load$isBinary <- !is.na(dat_load$n_cases)
dat_load$Neff <- dat_load$n
dat_load$Neff[dat_load$isBinary] <- round( (4/((1/dat_load$n_cases)+(1/dat_load$n_controls)))[dat_load$isBinary], 2)
dat_load$prevalence <- NA
dat_load$prevalence[dat_load$isBinary] <- (dat_load$n_cases/dat_load$n)[dat_load$isBinary]

# load phenotypic correlations, pairwise sample size
# (need early for finngen redundant phenotypes)
rrmat_both <- read.table("bothsexes_resid_corrmat.csv",header=T,row.names=1,stringsAsFactors=F,sep=',')
rownames(rrmat_both)[rownames(rrmat_both)=="isFemale"] <- "is_female"
colnames(rrmat_both) <- paste0("phen_",rownames(rrmat_both))

nnmat_both <- read.table("bothsexes_pairwise_complete_ns.csv",header=T,sep=',',stringsAsFactors=F,row.names=1)
```

```{r split_sex_dat, include=FALSE}
# split sex
dat <- dat_load[dat_load$sex == "both_sexes",]
datf <- dat_load[dat_load$sex == "female",]
datm <- dat_load[dat_load$sex == "male",]
```

<br>

***

# !!! TODOs

* corrmat with biomarkers (and check resulting sig thresholds)
* set date for new output files



# Executive Summary

This page documents the process for designating significantly heritable phenotypes in the UKB Round 2 GWAS. The goal is to identify a set of top line results for significantly "heritable" phenotypes from LD Score Regression (LDSR) for use in downstream analyses.

Main points discussed below are:

* Choose between analysis versions for a given phenotype, such as [whether to rank-normalize continuous phenotypes](#irnt)
* Select top-line result for [sex-specific phenotypes](#sex-spec-summary)
* Classify [confidence based on sample size, possible biases](#confidence)
* Declare [significance of LDSR $h^2_g$ results](#sig_thresh)

(Links go to conclusions for each point)

[Credits](#credits)

***

<br>

# Removing excess phenotypes

The [UKB Round 2 GWAS](https://github.com/Nealelab/UK_Biobank_GWAS) contains `r nrow(dat_load)` GWAS of `r length(unique(dat_load$phen_stem))` unique phenotype codes (`r length(unique(dat_load$phen_stem[dat_load$source=="phesant"]))` PHESANT + `r length(unique(dat_load$phen_stem[dat_load$source=="finngen"]))` FinnGEN + `r length(unique(dat_load$phen_stem[dat_load$source=="icd10"]))` ICD10 + `r length(unique(dat_load$phen_stem[dat_load$source=="biomarkers"]))` biomarkers + `r length(unique(dat_load$phen_stem[dat_load$source=="covariate"]))` covariates). For many of these phenotypes, however, there are multiple GWAS, due to:

* Consideration of both inverse rank-normal transformed (IRNT) and raw untransformed versions of `r length(unique(dat_load$phen_stem[dat_load$variable_type == "continuous_irnt"]))` continuous phenotypes
* Consideration of whether to include the dilution factor as a covariate for the `r length(unique(dat_load$phen_stem[dat_load$source=="biomarkers"]))` biomarker phenotypes
* Sex-stratified results for most phenotypes

There's also some redundancy among the FinnGEN codes constructed from ICD diagnoses. Our first task, then, is to get a "primary" result for each phenotype.

<br>

## Choosing whether to include dilution factor as a covariate for biomarker phenotypes

For the biomarker assays, UK Biobank has reported that some samples were unintentionally diluted ([pdf](http://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/biomarker_issues.pdf)) during processing. Although an effort has been made to estimate the dilution fraction and correct assay values accordingly, the estimated dilution fraction has also been reported for potential use in additional modelling. For instance, [other initial analyses of the biomarker data](https://www.biorxiv.org/content/10.1101/660506v1) have opted to include the dilution fraction as a covariate in regression analyses.

For the Neale Lab GWAS, the analysis was performed both with and without the dilution fraction as a covariate (along with the same GWAS covariates for age, sex, and PCs used for all phenotypes). We evaluate here whether to use the GWAS results with or without the dilution fraction covariate as the primary GWAS for the purposes of the ldsc $h^2_g$ analyses here.

<br>

### Hertiability

If the dilution fraction covariate controls for substantial noise in the phenotype, we may anticipate stronger $h^2_g$ results (higher point estimate, more significant) when the covariate is included. 

<div class="well">

```{r dilute, fig.align='center', echo=FALSE}

###########
# biomarker dilution fraction comparisons
###########

# merge pairs

biom <- dat_load[!is.na(dat_load$dilute),]
biodat <- merge(biom[biom$dilute==F & !startsWith(biom$phenotype,"30897_"),c("phenotype","description","h2_liability","h2_z","h2_p","intercept","intercept_z","intercept_p","sex")],
                biom[biom$dilute==T & !startsWith(biom$phenotype,"30897_"),c("phenotype","description","h2_liability","h2_z","h2_p","intercept","intercept_z","intercept_p","sex")],
                by=c("phenotype","description","sex"))
rm(biom)
```

```{r plotly_dummy, echo=F, warnings=F, message=F,include=F}
# to catch initial plotly package messages
plot_ly(x=rnorm(2),y=rnorm(2),type="scatter",mode="markers")
```

```{r dilute_h2_plot, fig.align='center', echo=FALSE}
# x=no dilution factor
# qref for diagonal reference line
qref1 <- seq(min(0,min(biodat$h2_liability.x,na.rm=T)),max(biodat$h2_liability.x,na.rm=T),.01)
pp1 <- plot_ly(biodat,
        x=~h2_liability.x,
        y=~h2_liability.y,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
        ) %>% add_trace(
          x=qref1,
          y=qref1,
          mode="lines",
          showlegend=F,
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="without dilution covariate"),
          yaxis = list(title="with dilution covariate"),
          title = "SNP-h^2 estimate",
          margin=list(b=65)
        )
qref2 <- seq(min(0,min(-log10(biodat$h2_p.x),na.rm=T)),max(-log10(biodat$h2_p.x),na.rm=T),.01)
pp2 <- plot_ly(biodat,
        x=~-log10(h2_p.x),
        y=~-log10(h2_p.y),
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
        ) %>% add_trace(
          x=qref2,
          y=qref2,
          mode="lines",
          showlegend=F,
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="without dilution covariate"),
          yaxis = list(title="with dilution covariate"),
          title = "-log10 SNP-h^2 p-value",
          margin=list(b=65)
        )
htmltools::div(
  style = "display: flex; flex-wrap: wrap; justify-content: center",
  htmltools::div(pp1),
  htmltools::div(pp2)
)
```

*Takeaway:* $h^2_g$ estimate and significance are not meaningfully affected by the addition of the dilution factor covariate.

</div>

### Intercept

If the dilution fraction is somehow correlated with the genetic data in a way that would lead to overall inflation of the GWAS results (e.g. some correlation with residual population structure), we may anticipate genome-wide inflation to be evident in the intercept results (higher point estimate, more significant) when the covariate is omitted. 

<div class="well">

```{r dilute_int_plot, fig.align='center', echo=FALSE}
# x=no dilution factor
# qref for diagonal reference line
qref1 <- seq(min(1,min(biodat$intercept.x,na.rm=T)),max(biodat$intercept.x,na.rm=T),.01)
pp1 <- plot_ly(biodat,
        x=~intercept.x,
        y=~intercept.y,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
        ) %>% add_trace(
          x=qref1,
          y=qref1,
          mode="lines",
          showlegend=F,
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="without dilution covariate"),
          yaxis = list(title="with dilution covariate"),
          title = "intercept estimate",
          margin=list(b=65)
        )
qref2 <- seq(min(0,min(-log10(biodat$intercept_p.x),na.rm=T)),max(-log10(biodat$intercept_p.x),na.rm=T),.01)
pp2 <- plot_ly(biodat,
        x=~-log10(intercept_p.x),
        y=~-log10(intercept_p.y),
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
        ) %>% add_trace(
          x=qref2,
          y=qref2,
          mode="lines",
          showlegend=F,
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="without dilution covariate"),
          yaxis = list(title="with dilution covariate"),
          title = "-log10 intercept p-value",
          margin=list(b=65)
        )
htmltools::div(
  style = "display: flex; flex-wrap: wrap; justify-content: center",
  htmltools::div(pp1),
  htmltools::div(pp2)
)

```

*Takeaway:* The intercept estimate and significance are not substantially affected by the addition of the dilution factor covariate. If anything, adding the dilution factor covariate reduces the stability of the intercept (lower significance) without affecting the point estimate.

</div>


### **Conclusion**

Overall, the the inclusion of the dilution factor covariate has minimal impact on the results for the biomarkers. Therefore in the interest of simplicity we treat the GWAS without the dilution factor covariate as the primary analysis for the biomarker phenotypes. (Results for the GWAS with the dilution factor covariate still appear in the complete results file though.) The only remaining variation in covariates across the analyses is that sex is omitted as a covariate in sex-specific GWAS.


```{r drop_dilute_irnt, echo=FALSE}
dat$keep <- rep(T, nrow(dat))
dat$notes <- rep("", nrow(dat))

dat$keep[dat$source=="biomarkers" & dat$dilute] <- F
dat$notes[grep("_raw",dat$phenotype)] <- "drop_bio_dilution"

dat_full <- dat
dat <- dat_full[dat$keep,]

rm(biodat)
```


<br>

## Choosing IRNT vs. raw untransformed continuous phenotypes

The Round 1 GWAS rank-normalized all continuous phenotypes. In Round 2, untransformed copies of the continuous phenotypes were also GWASed for the purposes of evaluating whether rank-normalizing was beneficial. Here we compare the raw and IRNT versions of all of the continuous phenotypes from PHESANT that were GWASed in `both_sexes` (i.e. that aren't sex-specific).

Specifically, we evaluate whether:

* IRNT vs. raw provide better $h^2_g$ results (i.e. higher $h^2_g$, smaller $h^2_g$ SE, and/or stronger $h^2_g$ significance)
* IRNT vs. raw provide better control of stratification (i.e. higher intercept, and/or stronger intercept significance)

<br>

### Heritability

We first look at heritability:

<div class="well">

```{r irnt_h2, fig.align='center', echo=FALSE}

###########
# raw vs irnt comparisons
###########

# merge of raw, irnt pairs
cont_dat <- dat[dat$phen_stem %in% dat$phen_stem[duplicated(dat$phen_stem)],]
foo_irnt <- cont_dat[grep("_irnt",cont_dat$phenotype),]
foo_raw <- cont_dat[grep("_raw",cont_dat$phenotype),]
# 
cont_merge <- merge(x=foo_irnt[,c("phenotype","description","phen_stem","h2_liability","h2_liability_se","h2_p","intercept","intercept_z","intercept_p","ratio")],
                    y=foo_raw[,c("phenotype","phen_stem","h2_liability","h2_liability_se","h2_p","intercept","intercept_z","intercept_p","ratio")],
                    by="phen_stem")

rm(foo_irnt)
rm(foo_raw)
rm(cont_dat)
```


```{r irnt_h2_plot, fig.align='center', echo=FALSE}
# x=irnt
# qref for diagonal reference line
qref <- seq(min(0,min(cont_merge$h2_liability.x,na.rm=T)),max(cont_merge$h2_liability.x,na.rm=T),.01)
pp <- plot_ly(cont_merge,
        x=~h2_liability.x,
        y=~h2_liability.y,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
        ) %>% add_trace(
          x=qref,
          y=qref,
          mode="lines",
          showlegend=F,
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="IRNT SNP-h^2"),
          yaxis = list(title="raw SNP-h^2"),
          margin=list(b=65)
        )
htmltools::div( pp, align="center")
```

*Takeaway:* $h^2_g$ results are generally consistent, but with higher $h^2_g$ for the IRNT versions of each phenotype.

<br>

```{r irnt_h2_p, echo=FALSE}

# h2 p
qref <- seq(min(0,min(-log10(cont_merge$h2_p.x),na.rm=T)),max(-log10(cont_merge$h2_p.x),na.rm=T),.01)
pp <- plot_ly(cont_merge,
        x=~-log10(h2_p.x),
        y=~-log10(h2_p.y),
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
) %>% add_trace(
  x=qref,
  y=qref,
  mode="lines",
  showlegend=F,
  hoverinfo="text",
  text=""
) %>% layout(
  xaxis = list(title="-log10(IRNT SNP-h^2 p)"),
  yaxis = list(title="-log10(raw SNP-h^2 p)"),
  margin=list(b=65)
)
htmltools::div( pp, align="center")
```

*Takeaway:* p-values for testing $h^2_g$ are mostly consistent between scalings, but IRNT does average more significant $h^2_g$ results, especially among the phenotypes that have high $h^2_g$. Compared to the observed differences in $h^2_g$, the moderate change in p-values here reflects that the SEs for $h^2_g$ are often also nominally larger for IRNT (not shown).

</div>

Taken together, these seem to point towards IRNT providing a net benefit to the LDSR $h^2_g$ results. 

<br>

### Intercept

Before adopting that conclusion, however, we also look at the results for the intercept term:

<div class="well">

```{r irnt_int, echo=FALSE}

# int
qref <- seq(min(1,min(cont_merge$intercept.x,na.rm=T)),max(cont_merge$intercept.x,na.rm=T),.01)
pp <- plot_ly(cont_merge,
        x=~intercept.x,
        y=~intercept.y,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
) %>% add_trace(
  x=qref,
  y=qref,
  mode="lines",
  showlegend=F,
  hoverinfo="text",
  text=""
) %>% layout(
  xaxis = list(title="IRNT intercept",range=c(.95,1.38)),
  yaxis = list(title="raw intercept",range=c(.95,1.38)),
  autosize = T,
  margin=list(b=65)
)
htmltools::div( pp, align="center" )
```

*Takeaway:* Intercepts are maybe slightly larger on average for IRNT versions of each phenotype (especially for intercepts 1.05-1.20; zoom plot out for additional outliers), but the differences are marginal. The largest differences seem to occur among the biomarkers and haemotology measures. Comparing these estimates with the mean $\chi^2$ values, the estimated intercept ratios remain mostly unchanged between the IRNT and raw versions (not shown). 

<br>

```{r irnt_int_p, echo=FALSE}

# for p-values beyond base r precision
cont_merge$int_nlogp_x_tmp <- -log10(cont_merge$intercept_p.x)
cont_merge$int_nlogp_y_tmp <- -log10(cont_merge$intercept_p.y)

cont_merge$int_nlogp_x_tmp[!is.finite(cont_merge$int_nlogp_x_tmp)] <- as.numeric(-log10(mpfr(0.5,64)*erfc(mpfr(cont_merge$intercept_z.x[!is.finite(cont_merge$int_nlogp_x_tmp)],64)/sqrt(mpfr(2,64)))))
cont_merge$int_nlogp_y_tmp[!is.finite(cont_merge$int_nlogp_y_tmp)] <- as.numeric(-log10(mpfr(0.5,64)*erfc(mpfr(cont_merge$intercept_z.y[!is.finite(cont_merge$int_nlogp_y_tmp)],64)/sqrt(mpfr(2,64)))))

# intercept p
qref <- seq(min(0,min(cont_merge$int_nlogp_x_tmp,na.rm=T)),max(max(cont_merge$int_nlogp_x_tmp,na.rm=T),300),.01)
pp <- plot_ly(cont_merge,
        x=~int_nlogp_x_tmp,
        y=~int_nlogp_y_tmp,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~description,
        width=400, height=400
) %>% add_trace(
  x=qref,
  y=qref,
  mode="lines",
  showlegend=F,
  hoverinfo="text",
  text=""
) %>% layout(
  xaxis = list(title="-log10(IRNT intercept p)",range=c(0,16)),
  yaxis = list(title="-log10(raw intercept p)",range=c(0,16)),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )

rm(qref)
rm(cont_merge)
```

*Takeaway:* Focusing here on the majority of phenotypes with moderate/nominally significant intercept results (zoom out for p-values out to 1e-450), the p-values are strongly consistent between the IRNT and raw untransformed phenotypes. IRNT intercepts are maybe marginally more significant on average.

One noteworthy outlier is the estimated dilution fraction for the biomarker data (code 30897), which has a much higher intercept in the IRNT version of the GWAS (mean $\chi^2 = `r signif(dat_load$mean_chi2[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],4)`$, intercept $= `r signif(dat_load$intercept[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],4)`$, SE $= `r signif(dat_load$intercept_se[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],2)`$, $p = `r signif(dat_load$intercept_p[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$) than in the GWAS of the raw value (mean $\chi^2 = `r signif(dat_load$mean_chi2[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],4)`$, intercept $= `r signif(dat_load$intercept[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],4)`$, SE $= `r signif(dat_load$intercept_se[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],2)`$, $p = `r signif(dat_load$intercept_p[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$). The reason for this strong difference is unclear, though it may relate to the [bimodal, left-skewed distribution of the dilution fraction estimate](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=30897). The SNP-heritability result is reassuringly null in either case (IRNT: $h^2_g = `r signif(dat_load$h2_liability[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$, $p = `r signif(dat_load$h2_p[dat_load$phenotype=="30897_irnt" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$; raw: $h^2_g = `r signif(dat_load$h2_liability[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$, $p = `r signif(dat_load$h2_p[dat_load$phenotype=="30897_raw" & !dat_load$dilute & dat_load$sex=="both_sexes"],3)`$), as would be expected for GWAS of an estimate of sample contamination in the lab. As a result we give limited weight to this outlier in evaluating the choice of IRNT vs. raw versions of the GWAS.

</div>

### **Conclusion** {#irnt}

Overall, the results are largely consistent regardless of the choice of IRNT or raw untransformed phenotypes. Since IRNT does appear to provide a marginal boost to the $h^2_g$ results, especially in terms of significance, we choose to treat the IRNT version as the primary analysis for continuous phenotypes. (Results for the raw, untransformed versions will still appear in the complete results file though.)

```{r keep_irnt, echo=FALSE}

dat_full$keep[dat_full$keep & grepl("_raw",dat_full$phenotype)] <- F
dat_full$notes[dat_full$keep & grepl("_raw",dat_full$phenotype)] <- "drop_cont_raw"

dat$keep[grepl("_raw",dat$phenotype)] <- F
dat <- dat[dat$keep,]

```


<br>

## Removing redundant FinnGEN codes

During review of the GWAS phenotypes, we identified some instances where a FinnGEN code corresponds to a phenotype that is identical to another GWASed FinnGEN code and in thus redundant. The most common case is pairs with codes `C_*` and `C3_*` with the same name, description,and sample size. For example, both `C_OTHER_SKIN` and `C3_OTHER_SKIN` are phenotypes for "Other malignant neoplasms of skin", and both have 14,402 cases and 346,792 controls. We identify and mark as redundant those phenotypes here.

<div class="well">

We can systematically identify these redundant pairs by confirming that the phenotypic correlation between the codes is 1 and that the phenotype is observed in the same individuals with the same number of cases. From that process, we identify the following phenotype pairs:

```{r duplicate_finngen, echo=F}

fg_rr <- rrmat_both[rownames(rrmat_both) %in% dat$phenotype[dat$source=="finngen"],
                    rownames(rrmat_both) %in% dat$phenotype[dat$source=="finngen"]]
fg_nn <- nnmat_both[rownames(nnmat_both) %in% dat$phenotype[dat$source=="finngen"],
                    rownames(nnmat_both) %in% dat$phenotype[dat$source=="finngen"]]

# get perfect correlation
fg_cor1 <- which(fg_rr==1, arr.ind = T)

# remove diagonal elements and lower triangle (to prevent symmetric duplicates)
fg_cor1 <- fg_cor1[!(fg_cor1[,1]>=fg_cor1[,2]),]

# get just phenotypes where sample size overlap matches full N
fg_cor1_n1 <- diag(as.matrix(fg_nn[match(rownames(fg_rr)[as.numeric(fg_cor1[,1])], rownames(fg_nn)), match(rownames(fg_rr)[as.numeric(fg_cor1[,1])], rownames(fg_nn))]))
fg_cor1_n2 <- diag(as.matrix(fg_nn[match(rownames(fg_rr)[as.numeric(fg_cor1[,2])], rownames(fg_nn)), match(rownames(fg_rr)[as.numeric(fg_cor1[,2])], rownames(fg_nn))]))
fg_cor1_n12 <- diag(as.matrix(fg_nn[match(rownames(fg_rr)[as.numeric(fg_cor1[,1])], rownames(fg_nn)), match(rownames(fg_rr)[as.numeric(fg_cor1[,2])], rownames(fg_nn))]))

fg_cor1 <- fg_cor1[(fg_cor1_n1 == fg_cor1_n2) & (fg_cor1_n2 == fg_cor1_n12),]

# confirm case count also matches
fg_cor1_case1 <- dat$n_cases[match(rownames(fg_rr)[as.numeric(fg_cor1[,1])], dat$phenotype)]
fg_cor1_case2 <- dat$n_cases[match(rownames(fg_rr)[as.numeric(fg_cor1[,2])], dat$phenotype)]

fg_cor1 <- fg_cor1[(fg_cor1_case1==fg_cor1_case2),]

# print pairs
fg_pairs <- cbind(rownames(fg_rr)[fg_cor1[,1]], rownames(fg_rr)[fg_cor1[,2]])

datatable(fg_pairs, 
		  rownames = F, 
		  colnames = c("Phenotype 1","Phenotype 2"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=nrow(fg_pairs), dom='t')#, fixedColumns=TRUE), 
)
```

<br>

</div>

### **Conclusion**

For these pairs, we drop the phenotype listed in the second column as redundant. This leads to the removal of `r length(unique(rownames(fg_rr)[fg_cor1[,2]]))` FinnGEN phenotype codes, leaving `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` unique phenotype codes among the GWAS.

```{r drop_finngen_dupe, echo=F}

dat_full$notes[dat_full$keep & (dat_full$phenotype %in% fg_pairs[,2])] <- "drop_finngen_dupe"
dat_full$keep[dat_full$phenotype %in% fg_pairs[,2]] <- F

dat$keep[dat$phenotype %in% fg_pairs[,2]] <- F
dat <- dat[dat$keep,]

rm(fg_nn)
rm(fg_rr)
```

<br>

## Sex-specific phenotypes

UKB includes a number of sex-specific phenotypes, meaning that not all phenotypes have a `both_sexes` version of the analysis. In addition, although some of these are specified by UKB and thus coded as such (e.g. all members of the non-applicable sex are marked as missing), others do not exclude non-applicable sex, for example treating them as controls. The Round 2 GWAS included strong efforts to address phenotypes with this issue, particularly among the PHESANT phenotypes, but we still have some GWAS where there's a `both_sexes` analysis of a sex-specific phenotype. Therefore the goal here is to verify that we have the appropriate version of each phenotype respecting sex-specificity where applicable.

Our process is as follows:

* For phenotypes where only a `male` or `female` version of the analysis exists (with no `both_sexes`), take that version.
* For phenotypes where both a `male` and `female` version of the analysis exists, verify that both sex-specific analyses have a non-trivial proportion of the sample size and of the number of cases. As long as that is true, take the `both_sexes` analysis, otherwise take the appropriate sex-specific analysis.
* For phenotypes with a `both_sexes` analysis but only one sex-stratified analysis, compare sample size and case count of the sex-specific analysis to the `both_sexes` analysis. If the sex-specific analysis is the dominant source of samples then use the sex-specific analysis, otherwise use the `both_sexes` analysis. 

We inspect the results of this process to ensure face validity of the concluded sex-specificity of the phenotypes.

```{r sex_spec_setup, echo=FALSE}
# setup male/female data
datf$phen_stem <- as.character(datf$phenotype)
datf$phen_stem[is.na(datf$n_cases)] <- as.character(sapply(datf$phenotype[is.na(datf$n_cases)],function(a) strsplit(a, "_")[[1]][1]))
datf$keep <- rep(T, nrow(datf))
datf$notes <- rep("", nrow(datf))
datf$keep[datf$source=="biomarkers" & datf$dilute] <- F
datf$notes[datf$source=="biomarkers" & datf$dilute] <- "drop_bio_dilution"
datf$notes[datf$keep & grepl("_raw",datf$phenotype)] <- "drop_cont_raw"
datf$keep[datf$keep & grepl("_raw",datf$phenotype)] <- F
datf$notes[datf$keep & (datf$phenotype %in% fg_pairs[,2])] <- "drop_finngen_dupe"
datf$keep[datf$phenotype %in% fg_pairs[,2]] <- F
datf_full <- datf
datf <- datf_full[datf$keep,]
datm$phen_stem <- as.character(datm$phenotype)
datm$phen_stem[is.na(datm$n_cases)] <- as.character(sapply(datm$phenotype[is.na(datm$n_cases)],function(a) strsplit(a, "_")[[1]][1]))
datm$keep <- rep(T, nrow(datm))
datm$notes <- rep("", nrow(datm))
datm$keep[datm$source=="biomarkers" & datm$dilute] <- F
datm$notes[datm$source=="biomarkers" & datm$dilute] <- "drop_bio_dilution"
datm$notes[datm$keep & grepl("_raw",datm$phenotype)] <- "drop_cont_raw"
datm$keep[datm$keep & grepl("_raw",datm$phenotype)] <- F
datm$notes[datm$keep & (datm$phenotype %in% fg_pairs[,2])] <- "drop_finngen_dupe"
datm$keep[datm$phenotype %in% fg_pairs[,2]] <- F
datm_full <- datm
datm <- datm_full[datm$keep,c("phenotype","phen_stem","description","n","n_cases","n_controls","keep","notes")]
```

<br>

### Single sex GWAS only

<div class="well">

```{r single_sex, echo=FALSE}
# female only
femonly <- datf[!(datf$phen_stem %in% dat$phen_stem),]

# male only
malonly <- datm[!(datm$phen_stem %in% dat$phen_stem),]

```

**Female-only** <button class="btn btn-outline-primary btn-sm" data-toggle="collapse" data-target="#FemaleOnly"> Show/Hide </button>  
<div id="FemaleOnly" class="collapse">
```{r femonly_list, echo=F, comment=NA}
paste0(femonly$description, " [", femonly$phenotype, "]")
rm(femonly)
```
</div>

<br>

**Male-only** <button class="btn btn-outline-primary btn-sm" data-toggle="collapse" data-target="#MaleOnly"> Show/Hide </button>  
<div id="MaleOnly" class="collapse">
```{r malonly_list, echo=F, comment=NA}
print(paste0(malonly$description, " [", malonly$phenotype, "]"))
rm(malonly)
```
</div>
<br>

*Takeaway:* Very strong face validity for each of these lists.

</div>

#### **Conclusion** 

Take these lists as-is.

<br>

### GWASed within each sex separately

<div class="well">

```{r both_sex_present, echo=F, comment=NA}

# in both male and female
phens_bothsex <- datf$phenotype[datf$phenotype %in% datm$phenotype]
phens_bothsex_idxf <- match(phens_bothsex, datf$phenotype)
phens_bothsex_idxm <- match(phens_bothsex, datm$phenotype)

# compare Ns
sex_ns <- data.frame(phenotype=phens_bothsex,
                     description=datf$description[phens_bothsex_idxf],
                     n_fem=datf$n[phens_bothsex_idxf],
                     n_case_fem=datf$n_cases[phens_bothsex_idxf],
                     n_control_fem=datf$n_controls[phens_bothsex_idxf],
                     n_mal=datm$n[phens_bothsex_idxm],
                     n_case_mal=datm$n_cases[phens_bothsex_idxm],
                     n_control_mal=datm$n_controls[phens_bothsex_idxm]) 

pp <- plot_ly(sex_ns,
        x=~n_fem,
        y=~n_mal,
        type="scatter",
        mode="markers",
        showlegend=F,
        hoverinfo="text",
        text=~paste0(
                "Phenotype: ", description,
                "<br>Female N: ", n_fem,
                "<br>Male N: ", n_mal,
                "<br>Proportion Female: ", round(n_fem/(n_fem+n_mal),3)),
        width=400, height=400
) %>% layout(
  xaxis = list(title="N in Female GWAS"),
  yaxis = list(title="N in Male GWAS"),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )
```

*Takeaway:* Sample size is nicely divided male/female for this set of phenotypes.

<br>

```{r both_sex_present_cases, echo=F, comment=NA}

pp1 <- plot_ly(sex_ns[!(is.na(sex_ns$n_case_fem) & is.na(sex_ns$n_case_mal)),],
        x=~n_case_fem/(n_case_fem+n_case_mal),
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Proportion of cases who are female", range=c(0,1)),
  title="cases",
  margin=list(b=65)
)


pp2 <- plot_ly(sex_ns[!(is.na(sex_ns$n_case_fem) & is.na(sex_ns$n_case_mal)),],
        x=~n_control_fem/(n_control_fem+n_control_mal),
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Proportion of controls who are female", range=c(0,1)),
  title="controls",
  margin=list(b=65)
)


htmltools::div(
  style = "display: flex; flex-wrap: wrap; justify-content: center;",
  htmltools::div(pp1),
  htmltools::div(pp2)
)
```

*Takeaway:* Cases and controls are also nicely balanced between males and females for most of these phenotypes. 

<br>

We can examine more closely the phenotypes in the tails of these distributions, with $>85\%$ of cases or controls coming from one sex:


<style>
table { white-space: nowrap; }
</style>
```{r both_sex_present_cases_outlier, echo=F, comment=NA}
shared_dat <- 
  sex_ns[ (sex_ns$n_control_fem/(sex_ns$n_control_fem+sex_ns$n_control_mal) > .85 |
         sex_ns$n_control_fem/(sex_ns$n_control_fem+sex_ns$n_control_mal) < .15 |
         sex_ns$n_case_fem/(sex_ns$n_case_fem+sex_ns$n_case_mal) > .85 | 
         sex_ns$n_case_fem/(sex_ns$n_case_fem+sex_ns$n_case_mal) < .15) &
         !is.na(sex_ns$n_case_fem),]


datatable(shared_dat, 
		  rownames = F, 
		  colnames = c("Code","Phenotype","N Female","N Case (F)","N Con. (F)","N Male","N Case (M)","N Con. (M)"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=50, dom='t')#, fixedColumns=TRUE), 
)

```
<!-- </div> -->
*Note:* Table can be scrolled to the right for sample sizes.

*Takeaway:* We note that although these are strongly sex-biased, they are not necessarily sex-specific. For example, this list contains a large number of codes for jobs with a history of being strongly gendered (e.g. nursing) and treatments most commonly recommended for strongly sex-biased phenotypes (e.g. calcium supplements for osteoporosis). 

[*NB:* The majority of these phenotypes will also end up below our effective sample size threshold for high confidence results, as described below, and thus will not be a primary contributor to the top level heritability results regardless of the treatment of these phenotypes here.]

</div>

#### **Conclusion** 

Although a handful of these phenotypes are strongly sex-biased, none appear to be fully sex-specific. Therefore we take the `both_sexes` GWAS as the primary result for all phenotypes in this set.

<br>

### GWASed in `both_sexes` and one sex

```{r one_sex, echo=F}
dat_one_f <- dat[(dat$phenotype %in% datf$phenotype & !(dat$phenotype %in% datm$phenotype)),]
dat_one_m <- dat[(dat$phenotype %in% datm$phenotype & !(dat$phenotype %in% datf$phenotype)),]
```

There are `r nrow(dat_one_f)+nrow(dat_one_m)` phenotypes with a GWAS in `both_sexes` and one sex but not the other (specifically, `r nrow(dat_one_m)` in males and `r nrow(dat_one_f)` in females).

For all phenotypes in this category, we evaluate what proportion of their total sample size comes from the GWASed sex.

<div class="well">

```{r one_sex_n, echo=F}

phens_onesex_idxf <- match(dat_one_f$phenotype, datf$phenotype)
phens_onesex_idxm <- match(dat_one_m$phenotype, datm$phenotype)

# compare Ns
onesexf_ns <- data.frame(phenotype=dat_one_f$phenotype,
                      description=datf$description[phens_onesex_idxf],
                      n=dat_one_f$n,
                      n_case=dat_one_f$n_case,
                      n_control=dat_one_f$n_controls,
                      n_sex=datf$n[phens_onesex_idxf],
                      n_case_sex=datf$n_cases[phens_onesex_idxf],
                      n_control_sex=datf$n_controls[phens_onesex_idxf]) 
onesexm_ns <- data.frame(phenotype=dat_one_m$phenotype,
                      description=datm$description[phens_onesex_idxm],
                      n=dat_one_m$n,
                      n_case=dat_one_m$n_case,
                      n_control=dat_one_m$n_controls,
                      n_sex=datm$n[phens_onesex_idxm],
                      n_case_sex=datm$n_cases[phens_onesex_idxm],
                      n_control_sex=datm$n_controls[phens_onesex_idxm]) 
onesex_ns <- rbind(onesexf_ns, onesexm_ns)
rm(onesexf_ns)
rm(onesexm_ns)

pp <- plot_ly(onesex_ns,
        x=~n_sex/n,
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Prop. samples from GWASed sex", range=c(0,1)),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )

rm(dat_one_f)
rm(dat_one_m)
rm(datf)
rm(datm)
```

The visible outliers from this distribution ($>85\%$ of samples coming from the GWASed sex) are:

```{r one_sex_n_outlier, echo=F, comment=NA}
shared_dat <- onesex_ns[onesex_ns$n_sex/onesex_ns$n > 0.85,c("phenotype","description","n","n_sex")]

datatable(shared_dat, 
		  rownames = F, 
		  colnames = c("Code","Phenotype","Total N","GWAS Sex N"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=nrow(onesex_ns), dom='t')#, fixedColumns=TRUE), 
)

```
*Note:* Table can be scrolled to the right for sample sizes.

*Takeaway:* The majority of these outlying phenotypes clearly either are sex-specific (and just have a redundant `both_sexes` GWAS) or should be (i.e. the collection of traits here where only 2 individuals aren't in the primary sex). Note that this includes items that aren't on their face sex-specific but were asked as part of a sex-specific questionnaire (e.g. 6153 and 6177, administered to self-reported females and males, respectively).

The one exception is 5959 ("Previously smoked cigarettes on most/all days") which is predominantly male ($96.6\%$) but not exclusively gendered. The strong sex bias comes from it being a follow-up question only administered to individuals who report currently smoking "on most or all days" and who "mainly" smoke "cigars or pipes". 

</div>

For binary phenotypes on this class (excluding the ones clearly indicated as sex-specific above), we additionally look at the proportion of cases and controls coming from the GWASed sex:

<div class="well">

```{r one_sex_case, echo=F}

pp1 <- plot_ly(onesex_ns[!is.na(onesex_ns$n_case) & !(onesex_ns$n_sex/onesex_ns$n > 0.97),],
        x=~n_case_sex/n_case,
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Prop. cases from GWASed sex", range=c(0,1)),
  title = "cases",
  margin=list(b=65)
)

pp2 <- plot_ly(onesex_ns[!is.na(onesex_ns$n_case) & !(onesex_ns$n_sex/onesex_ns$n > 0.97),],
        x=~n_control_sex/n_control,
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Prop. controls from GWASed sex", range=c(0,1)),
  title = "controls",
  margin=list(b=65)
)

htmltools::div(
  style = "display: flex; flex-wrap: wrap; justify-content: center",
  htmltools::div(pp1),
  htmltools::div(pp2)
)
```

The outliers from these two distributions, again using the $>85\%$ threshold, are: 

```{r one_sex_ncase_outlier, echo=F, comment=NA}
shared_dat <- onesex_ns[
                          !is.na(onesex_ns$n_case) & 
                          !(onesex_ns$n_sex/onesex_ns$n > 0.97) &
                          ((onesex_ns$n_case_sex/onesex_ns$n_case > 0.85) | (onesex_ns$n_control_sex/onesex_ns$n_control > 0.85)),
                        c("phenotype","description","n_case","n_case_sex","n_control","n_control_sex")]

datatable(shared_dat, 
		  rownames = F, 
		  colnames = c("Code","Phenotype","Total Case","GWAS Sex Case","Total Control","GWAS Sex Control"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=nrow(onesex_ns), dom='t')#, fixedColumns=TRUE), 
)
```
*Note:* Table can be scrolled to the right for sample sizes.

*Takeaway:* This list of phenotypes with cases and/or controls primarily from one sex is dominanted by job codes and medical outcomes that are either strongly sex biased or (in the case of some medical phenotypes, e.g. pregnancy-related ICD codes) sex-specific. Considering the $97\%$ threshold used to evaluate total sample size above, none of the phenotypes with $85-97\%$ of cases or controls from a single sex are definitionally-sex specific, instead they are all instances where cases/controls from the rarer sex are entirely plausible. The `both_sexes` analysis of these phenotypes therefore seems appropriate the treat as the "primary" analysis (though we revisit expectations about the stability of these results below).

For the remaining phenotypes with >$97\%$ of cases and/or controls coming from the GWASed sex (relisted below), we see three clear scenarios:

* job codes with a very strong sex bias, up to and including jobs only reported in a single sex (e.g. dinner lady, midwife, bricklayer, pipe fitter)
* medical ICD codes that are sex-specific (e.g. disorders of the prostate or overies)
* medical ICD codes that are very strongly sex-biased but can occur in either sex (e.g. breast cancer)

Following the standard applied above, we opt to use the sex-specific GWAS as the primary result for the truely sex-specific medical phenotypes, but keep the `both_sexes` analysis for the other two scenarios where cases/controls from both sexes are reasonable despite their rarity.

```{r one_sex_ncase_outlier97, echo=F, comment=NA}
shared_dat <- onesex_ns[
                          !is.na(onesex_ns$n_case) & 
                          !(onesex_ns$n_sex/onesex_ns$n > 0.97) &
                          ((onesex_ns$n_case_sex/onesex_ns$n_case > 0.97) | (onesex_ns$n_control_sex/onesex_ns$n_control > 0.97)),
                        c("phenotype","description","n_case","n_case_sex","n_control","n_control_sex")]

datatable(shared_dat, 
		  rownames = F, 
		  colnames = c("Code","Phenotype","Total Case","GWAS Sex Case","Total Control","GWAS Sex Control"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=nrow(onesex_ns), dom='t')#, fixedColumns=TRUE), 
)
```
*Note:* Table can be scrolled to the right for sample sizes.

</div>

```{r resolve_sex_spec, echo=F, comment=NA}
# previously have dat, datf, datm
# with _full versions of each that additionally have "keep" and "notes"
# here: assemble kept versions from sex checks


# no both_sex = keep the sex-specific
# = no existing entries that get dropped 

# both sexes have a separate gwas = keep both_sex
# = drop the sex-specific entries
datm_full$keep[datm_full$phenotype %in% datf_full$phenotype] <- F
datm_full$notes[(datm_full$phenotype %in% datf_full$phenotype) & datm_full$notes == ""] <- "both_sexes_gwased"
datf_full$keep[datf_full$phenotype %in% datm_full$phenotype] <- F
datf_full$notes[(datf_full$phenotype %in% datm_full$phenotype) & datf_full$notes == ""] <- "both_sexes_gwased"


# gwas in one sex+both, and <97% n/case/control from one = keep both_sexes
idxm <- match(onesex_ns$phenotype[ 
                                    (onesex_ns$n_sex / onesex_ns$n < 0.97) &
                                    (is.na(onesex_ns$n_case) |
                                    (!is.na(onesex_ns$n_case) & (onesex_ns$n_case_sex/onesex_ns$n_case < 0.97) & 
                                                                (onesex_ns$n_control_sex/onesex_ns$n_control < 0.97)))
                                  ],
              datm_full$phenotype)
idxm <- idxm[!is.na(idxm)]
idxf <- match(onesex_ns$phenotype[ 
                                    (onesex_ns$n_sex / onesex_ns$n < 0.97) & 
                                    (is.na(onesex_ns$n_case) |
                                    (!is.na(onesex_ns$n_case) & (onesex_ns$n_case_sex/onesex_ns$n_case < 0.97) & 
                                                                (onesex_ns$n_control_sex/onesex_ns$n_control < 0.97)))
                                  ],
              datf_full$phenotype)
idxf <- idxf[!is.na(idxf)]

datm_full$keep[idxm] <- F
datm_full$notes[idxm[datm_full$notes[idxm]==""]] <- "not_sex_spec"
datf_full$keep[idxf] <- F
datf_full$notes[idxf[datf_full$notes[idxf]==""]] <- "not_sex_spec"


# gwas in one sex+both, and n > 97% from one = single sex
idx <- match(onesex_ns$phenotype[onesex_ns$n_sex / onesex_ns$n >= 0.97], dat_full$phenotype)
dat_full$keep[idx] <- F
dat_full$notes[idx[dat_full$notes[idx]==""]] <- "sex_spec_n"


# gwas in one sex+both, and ncas/con sex spec (>.997) and not job codes = use single sex gwas
idx <- match(onesex_ns$phenotype[(onesex_ns$n_sex / onesex_ns$n < 0.97) &
                                 !is.na(onesex_ns$n_case) &
                                  (onesex_ns$n_case_sex / onesex_ns$n_case > 0.997 | 
                                   onesex_ns$n_control_sex / onesex_ns$n_control > 0.997) &
                                  (unlist(lapply(onesex_ns$description,function(a) unlist(strsplit(as.character(a), split = " "))[1])) != "Job")], 
             dat_full$phenotype)
dat_full$keep[idx] <- F
dat_full$notes[idx[dat_full$notes[idx]==""]] <- "sex_spec_ncase"

# gwas in one sex+both, and ncas/con not sex spec (<.997) or job codes = use both_sex gwas
idxm <- match(onesex_ns$phenotype[onesex_ns$n_sex / onesex_ns$n < 0.97 &
                                  !is.na(onesex_ns$n_case) &
                                  (onesex_ns$n_case_sex / onesex_ns$n_case > 0.97 | 
                                   onesex_ns$n_control_sex / onesex_ns$n_control > 0.97) &
                                  ((onesex_ns$n_case_sex / onesex_ns$n_case < 0.997 & 
                                   onesex_ns$n_control_sex / onesex_ns$n_control < 0.997) | 
                                   (unlist(lapply(onesex_ns$description,function(a) unlist(strsplit(as.character(a), split = " "))[1])) == "Job"))], 
             datm_full$phenotype)
idxm <- idxm[!is.na(idxm)]
datm_full$keep[idxm] <- F
datm_full$notes[idxm[datm_full$notes[idxm]==""]] <- "non_sexspec_ncase_rare"

idxf <- match(onesex_ns$phenotype[onesex_ns$n_sex / onesex_ns$n < 0.97 &
                                  !is.na(onesex_ns$n_case) &
                                  (onesex_ns$n_case_sex / onesex_ns$n_case > 0.97 | 
                                   onesex_ns$n_control_sex / onesex_ns$n_control > 0.97) &
                                  ((onesex_ns$n_case_sex / onesex_ns$n_case < 0.997 & 
                                   onesex_ns$n_control_sex / onesex_ns$n_control < 0.997) | 
                                   (unlist(lapply(onesex_ns$description,function(a) unlist(strsplit(as.character(a), split = " "))[1])) == "Job"))], 
             datf_full$phenotype)
idxf <- idxf[!is.na(idxf)]
datf_full$keep[idxf] <- F
datf_full$notes[idxf[datf_full$notes[idxf]==""]] <- "non_sexspec_ncase_rare"

dat <- rbind(dat_full[dat_full$keep,],datf_full[datf_full$keep,],datm_full[datm_full$keep,])

```

#### **Conclusion** 

For all phenotypes in this set (i.e. having GWAS in `both_sexes` and one sex, but missing for the other sex), if $<97\%$ of the total sample size and of the cases and controls (where applicable) come from a single sex then we treat the `both_sexes` GWAS as the "primary" analysis of that phenotype. If $>97\%$ of the total sample size comes from a single sex then we adopt the sex-specific result. Otherwise if $>97\%$ of cases and/or controls come from a single sex and the phenotype is by definition expect to be sex-specific (e.g. many ICD codes, but excluding job code) then we adopt the sex-specific GWAS as the primary GWAS, otherwise we use the `both_sexes` GWAS. 

<br>

### Summary {#sex-spec-summary}

To summarize, after excluding biomarker GWAS with the dilution factor covariate, `raw` versions of continuous phenotypes, and the redundant FinnGEN codes, there are `r nrow(dat_load[!(!is.na(dat_load$dilute) & dat_load$dilute) & !grepl("_raw",dat_load$phenotype) & !(dat_load$phen_stem %in% fg_pairs[,2]),])` total GWAS.

```{r start_sex_sum, echo=F}
# summary before resolving sex
table(dat_load$source[!(!is.na(dat_load$dilute) & dat_load$dilute) & !grepl("_raw",dat_load$phenotype) & !(dat_load$phen_stem %in% fg_pairs[,2])],dat_load$sex[!(!is.na(dat_load$dilute) & dat_load$dilute) & !grepl("_raw",dat_load$phenotype) & !(dat_load$phen_stem %in% fg_pairs[,2])])
```

Following the above process of looking at sex balance of the available GWAS, we keep as the primary GWAS for the `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` phenotypes:

* `both_sexes` GWAS for phenotypes with both `male` and `female` GWAS (`r sum(datf_full$notes=="both_sexes_gwased")` phenotypes)

* `both_sexes` GWAS for phenotypes with neither `male` nor `female` GWAS, i.e. due to low sample size or case counts (`r sum(!(dat_full$phenotype[dat_full$keep] %in% datf_full$phenotype) & !(dat_full$phenotype[dat_full$keep] %in% datm_full$phenotype))` phenotypes)

* single-sex GWAS for phenotypes with no `both_sexes` GWAS (`r sum(!(datm_full$phenotype %in% dat_full$phenotype))+sum(!(datf_full$phenotype %in% dat_full$phenotype))` phenotypes)

* single-sex GWAS available for phenotypes where $>97\%$ of the total sample size comes from a single sex (`r sum(dat_full$notes=="sex_spec_n")` phenotypes)

* single-sex GWAS available for phenotypes where $>99.7\%$ of the total cases or controls comes from a single sex (which is sufficient the distinguish sex-specific vs. strongly sex-biased biomedical phenotypes), excluding job codes (`r sum(dat_full$notes=="sex_spec_ncase")` phenotypes) 

* `both_sexes` GWAS for all remaining phenotypes with only one single-sex GWAS, i.e. job codes and phenotypes where $<97\%$ of the total samples and $<99.7\%$ of the total cases and controls are from a single sex (`r sum(datf_full$notes=="not_sex_spec")+sum(datm_full$notes=="not_sex_spec")+ sum(datf_full$notes=="non_sexspec_ncase_rare")+sum(datm_full$notes=="non_sexspec_ncase_rare")` phenotypes)


The resulting breakdown of the sexes used as the primary GWAS for the `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` unique phenotypes is:
```{r check_sex_sum, echo=F}
# summary after resolving sex
table(dat$source,dat$sex)
```

<br>


***

# Minimum sample size requirements

The above process leads us to a "primary" $h^2_g$ result for each of the `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` unique phenotypes in the Round 2 GWAS. We know, however, that the sample size (or effective sample size) for many of these phenotypes is quite low. For example, case counts are quite small for most ICD codes and job codes. To avoid unnecessary multiple testing we therefore aim to identify the minimum (effective) sample size required to provide sufficient power to make LDSR analysis viable. [*NB:* We focus here on a bare minimum in terms of power, we'll return to the question of bias later.]

*Goal:* determine the minimum (effective) sample size where we'd expect to have some useful level of power to detect a reasonable $h^2_g$.

<br>

## Question 1: What's the relationship between sample size and precision for LDSR?

<div class="well">
  
  To evaluate the effective sample size required to have power in LDSR analyses, we consider the relationship between $N_{eff}$ and the observed standard error (SE) for the LDSR $h^2_g$ estimate for the `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` Round 2 phenotypes.

```{r neff_se, echo=F}
# for color scaling
dat$h2_liab <- dat$h2_liability
dat$h2_liab[dat$h2_liab < 0] <- 0
dat$h2_liab[dat$h2_liab > .5] <- 0.5

# handle p=0
dat$int_p_text <- as.character(signif(dat$intercept_p, 3))
dat$int_p_text[dat$intercept_p==0] <- as.character(format(mpfr(0.5,64)*erfc(mpfr(dat$intercept_z[dat$intercept_p==0],64)/sqrt(mpfr(2,64))),max.digits=3,scientific=T))

pp <- plot_ly(dat,
        x=~Neff,
        y=~h2_liability_se,
        type="scatter",
        mode="markers",
        color=~h2_liab,
        colors=c("blue","darkorange"),
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  layout(xaxis=list(title="Neff"),
         yaxis=list(title="SE of SNP-h^2 estimate (liability)"),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```

*Takeaway:* There's a clear inverse relationship between $N_{eff}$ and the SE of the $h^2_g$ estimate. The SE is also very large (e.g. wider than the 0-1 range for $h^2$) at small effective sample sizes.

<br>

For both visualization and modelling, it's useful to look at this relationship in terms of the inverse variance ($1/SE^2$):

```{r neff_se_inv, echo=F}


pp <- plot_ly(dat,
        x=~Neff,
        y=~1/h2_liability_se^2,
        type="scatter",
        mode="markers",
        color=~h2_liab,
        colors=c("blue","darkorange"),
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  layout(xaxis=list(title="Neff"),
         yaxis=list(title="1/SE^2 for SNP-h^2 estimate (liability)"),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```

*Takeaway:* There's a nearly linear relationship between $N_{eff}$ and $1/SE^2$. This relationship is highly heteroskedastic, with much greater variability in the inverse variance when $N_{eff}$ is large.

<br>

We can model this observed relationship in order to establish the "expected" inverse variance as a function of $N_{eff}$. Given the observed heteroskedasticity, and that our primary interest is in the error variance at small sample sizes, we consider a weighted regression with weights inversely proportional to sample size. Based on the plot above we also allow for quadratic curvature in the relationship with $N_{eff}$, and also compare regression to a loess fit.

```{r neff_se_inv_fit, echo=F}
dat$Neff_sq <- (dat$Neff)^2

mod1 <- lm((1/h2_liability_se^2) ~ Neff + Neff_sq -1,data=dat, weights = 1/Neff^3)
llmod <- loess((1/h2_liability_se^2) ~ Neff, data = dat, span=0.2)

dat$pred_h2liab_se <- 1/sqrt(llmod$fitted)  # save for later 

# summary(mod1)

pp <- plot_ly(dat,
        x=~Neff,
        y=~1/h2_liability_se^2,
        type="scatter",
        mode="markers",
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  add_trace(x=~Neff[order(Neff)],
            y=~mod1$fitted.values[order(Neff)],
            mode="lines",
            showlegend=F,
            hoverinfo="text",
            text="") %>%
  add_trace(x=llmod$x[order(llmod$x)],
            y=llmod$fitted[order(llmod$x)],
            showlegend=F,
            mode="lines",
            hoverinfo="text",
            text="") %>%
  layout(xaxis=list(title="Neff"),
         yaxis=list(title="1/SE^2 for SNP h^2 estimate (liability)"),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```
*Note:* Orange = regression, green = loess. 

<br>

Of these, the loess fit appears to better fit the overall trend of the data, especially when focusing on smaller sample sizes (as is visible when zooming the above plot). Note the smaller sample sizes are the range relevant to the current question of the minimum viable sample size for ldsc. 


```{r neff_se_lowN_fit, echo=F}

pp <- plot_ly(dat,
        x=~Neff,
        y=~h2_liability_se,
        type="scatter",
        mode="markers",
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  add_trace(x=~Neff[order(Neff)],
            y=~1/sqrt(mod1$fitted.values[order(Neff)]),
            mode="lines",
            showlegend=F,
            hoverinfo="text",
            text="") %>%
  add_trace(x=llmod$x[order(llmod$x)],
            y=1/sqrt(llmod$fitted[order(llmod$x)]),
            showlegend=F,
            mode="lines",
            hoverinfo="text",
            text="") %>%
  layout(xaxis=list(title="Neff",range=c(0,5000)),
         yaxis=list(title="SE for SNP-h^2 estimate (liability)", range=c(0,0.35)),
         margin=list(b=65))
htmltools::div( pp, align="center" )

rm(mod1)

```

<br>

We adopt the loess model (green) for predicting SEs from sample size for the rest of this section.

</div>

<br>

## Question 2: Power as a function of expected SE

<div class="well">

Given the above model for expected SEs as a function of sample size, and assuming the SEs are well calibrated, we can then turn these modelled SEs into a power analysis. 

Specifically, we ask for a given true SNP-heritability, sample size and p-value threshold what the probability is of the estimated $h^2_g$ divided by its SE exceeding to corresponding critical value for the Z statistic, assuming the sampling variation of the estimated estimated $h^2_g$ and it's estimated SE both match the expected SE based on sample size given by the above model. We focus on here power at $p < .05$ without any multiple testing correction in the interest of providing results relevant to hypotheses that include look-ups of $h^2_g$ for a single phenotype (as opposed to scans across all available UKB phenotypes). We'll return to the question of which results we'd consider significant in the context of looking at all `r length(unique(dat_load$phen_stem[!(dat_load$phen_stem %in% fg_pairs[,2])]))` phenotypes later.

```{r neff_power_curve_reg, echo=F}

# h2hat = N(h2, se^2)
# z = h2hat/se = N(h2/se, 1)
# power = pnorm(z_alpha, mean=h2/se, var=1, lower=F)

pow_pred_points <- dat[order(dat$Neff),c("Neff","pred_h2liab_se")]

qq <- c(seq(1,nrow(pow_pred_points)-1,10),nrow(pow_pred_points))
pow_pred_points <- pow_pred_points[qq,]

### set up plots for different p-val thresholds
# with a range of h2 values

pp1 <- plot_ly(pow_pred_points,
               x=~Neff,
               y=~pnorm(qnorm(.05,lower=F), mean = .3/pred_h2liab_se, sd=1, lower.tail = F),
               type="scatter",
               mode="lines",
               name="SNP-h^2 = 0.3",
               showlegend=T,
               hoverinfo="none",
               height=400, width=400
      ) %>% add_trace(
              x=~Neff,
              y=~pnorm(qnorm(.05,lower=F), mean = .2/pred_h2liab_se, sd=1, lower.tail = F),
              mode="lines",
              name="SNP-h^2 = 0.2"
      ) %>% add_trace(
              x=~Neff,
              y=~pnorm(qnorm(.05,lower=F), mean = .1/pred_h2liab_se, sd=1, lower.tail = F),
              mode="lines",
              name="SNP-h^2 = 0.1"
      ) %>% add_trace(
              x=~Neff,
              y=~pnorm(qnorm(.05,lower=F), mean = .05/pred_h2liab_se, sd=1, lower.tail = F),
              mode="lines",
              name="SNP-h^2 = 0.05"              
      ) %>% layout(
        xaxis = list(title = "Effective N", range=c(0,30000)),
        yaxis = list(title= "Estimated Power", range=c(0,1),
        margin=list(b=65))
      )

htmltools::div( pp1, align="center" )

```

Note that this is a bit more empirical than a formal power analysis. We're relying on the average observed SE reported for the ldsc $h^2_g$ estimates rather than some theoretical expectation for the SE. There's also likely a relationship between the SE and the true $h^2_g$ (and corresponding genetic architecture), as evidenced by the previous plots of precision vs. sample size colored by $h^2_g$ estimate, that we do not account for in this power estimate. Nevertheless, we use this modelled estimate of power as a useful rough benchmark for evaluating what range of sample sizes to include in this $h^2_g$ analysis.

</div>

<br>
  
## Question 3: What $h^2_g$ is worth detecting?

<div class="well">

Now that we have rough estimates of power as a function of $h^2_g$ and sample size, the question is what $h^2_g$ is relevant to have power to detect. 

If we look at the UKB phenotypes with the larges sample sizes (i.e. $N_{eff}$>300k, where there's no worry about power) we find that the vast majority of phenotypes have $h^2_g$ estimates $\leq 0.3$, with a somewhat bimodal distribution (overall mean=`r round(mean(dat$h2_liability[dat$Neff>300000]),3)`, median=`r round(median(dat$h2_liability[dat$Neff>300000]),3)`).

```{r h2_high_neff, echo=F}

pp <- plot_ly(dat[dat$Neff > 300000,],
        x=~h2_liability,
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="SNP-h^2 (liability)", range=c(-0.1,0.6),
  margin=list(b=65))
)
htmltools::div( pp, align="center" )
```

<br>

From the observed $h^2_g$ distribution, is appears the phenotypes with larger estimated SNP-heritability tend to have estimates around $h^2_g=0.2$ or slightly larger. We can then orient our decisions on sample size around having power to detect $h^2_g \geq 0.2$.

</div>

<br>


### **Conclusion**

```{r required_neff, echo=F}

pred_pow <- pnorm(qnorm(.05,lower=F), mean = .2/dat$pred_h2liab_se, sd=1, lower.tail = F)

req_neff <- min(dat$Neff[pred_pow > 0.8])

req_neff_round <- 4500

rm(pred_pow)

```

From the above estimated power analysis, based on a loess fit of the observed SE of $h^2_g$ estimates as a function of effective N, we estimate needing $N_{eff}$=`r req_neff` to have at least 80% power to detect $h^2_g \geq 0.2$ at nominal significance ($p < .05$). We take 80% power as a standard goal for having a "well-powered" analysis, and focus on $h^2_g \geq 0.2$ and $p < .05$ for the reasons described above.

For the sake of having a round number, and choosing to err slightly towards being inclusive in the analysis, we take this fitted value and round down to $N_{eff}=`r req_neff_round`$. We exclude `r sum(dat$Neff <= req_neff_round)` phenotypes with $N_{eff} \leq `r req_neff_round`$ from further consideration in the LDSR $h^2_g$ analysis based on this threshold, leaving `r sum(dat$Neff > req_neff_round)` phenotypes.

[*NB:* We're lenient here largely because we know much more stringent criteria on $N_{eff}$ will be applied below in defining "low confidence" results.]

```{r apply_min_n, echo=F}
# also setup here to track confidence
dat$confidence <- "high"
dat_full$confidence = "high"
datm_full$confidence = "high"
datf_full$confidence = "high"

dat$isNotPrimary <- !dat$keep
dat_full$isNotPrimary <- !dat_full$keep
datm_full$isNotPrimary <- !datm_full$keep
datf_full$isNotPrimary <- !datf_full$keep

dat_full$confidence[dat_full$isNotPrimary] = "NA_(not_primary)"
datm_full$confidence[datm_full$isNotPrimary] = "NA_(not_primary)"
datf_full$confidence[datf_full$isNotPrimary] = "NA_(not_primary)"

dat$isBadPower <- F
dat$isBadPower[dat$Neff <= req_neff_round] <- T
dat$confidence[dat$isBadPower & dat$confidence=="high"] <- "none"

dat_full$isBadPower <- F
dat_full$isBadPower[dat_full$Neff<=req_neff_round] <- T
dat_full$confidence[dat_full$isBadPower & dat_full$confidence=="high"] <- "none"

datm_full$isBadPower <- F
datm_full$isBadPower[datm_full$Neff<=req_neff_round] <- T
datm_full$confidence[datm_full$isBadPower & datm_full$confidence=="high"] <- "none"

datf_full$isBadPower <- F
datf_full$isBadPower[datf_full$Neff<=req_neff_round] <- T
datf_full$confidence[datf_full$isBadPower & datf_full$confidence=="high"] <- "none"

dat <- dat[!dat$isBadPower,]
```

<br>

***

# Low confidence results

The above set of conditions identifies `r nrow(dat)` phenotypes that avoid redundancy for encoding and sex-specific results and reach a minimum effective sample size ($N_{eff}$) necessary for LDSR analysis to be viable in terms of power.

These thresholds may be considered a bare minimum. We now consider instances among these `r nrow(dat)` phenotypes where we may still be pessimistic about the accuracy of the LDSR results. In particular, we evaluate phenotypes where the SEs are larger than they "should" be based on sample size, and revisit [previous concerns](http://www.nealelab.is/blog/2017/9/20/insights-from-estimates-of-snp-heritability-for-2000-traits-and-disorders-in-uk-biobank) about bias in LDSR $h^2_g$ estimates at low $N_{eff}$. 

<br>


## Potential biases at low effective N

<div class="well">

In the first round of UKB GWAS from the Neale lab, we highlighted [possible biases](http://www.nealelab.is/blog/2017/9/20/insights-from-estimates-of-snp-heritability-for-2000-traits-and-disorders-in-uk-biobank) in the LDSR $h^2_g$ estimate at low $N_{eff}$. In particular, we observed signs of attenuated $h^2_g$ estimates for phenotypes with $N_{eff} < 10,000$. We reassess that trend here. 

```{r n_bias, echo=F}
ll <- loess(h2_liability ~ Neff, data=dat, span = 1)

pp <- plot_ly(dat,
              x=~Neff,
              y=~h2_liability,
              type="scatter",
              mode="markers",
              width=800,height=300,
              hoverinfo="text",
              text = ~paste0(
                "Phenotype: ", description,
                "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
                "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
                "<br>Effective N: ", Neff)) %>%
  add_trace(x=ll$x[order(ll$x)],
            y=ll$fitted[order(ll$x)],
            showlegend=F,
            mode="lines",
            hoverinfo="text",
            text="") %>%
  layout(yaxis=list(title="SNP-h^2 (liability)", range=c(-.25,.5)),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```

*Note*: Plot restricted to `r nrow(dat)` phenotypes passing $N_{eff}$ threshold. Zoom out to see $h^2_g$ outliers.

*Takeway:* Some mild attenuation in $h^2_g$ is seen below $N_{eff} = 100,000$, but it's as not as severe nor as sharply limited to $N_{eff} < 10,000$ as observed in round 1.

</div>

<br>

### Question 1: results changed as a function of mix of questions?

<div class="well">

One possible hypothesis is that the change in the shape of attenuation reflects the changing mix of phenotypes in the Round 2 GWAS release. In particular, there's a large number of additional diet items with $N_{eff} \approx 50,000$ and mental health items at $N_{eff} \approx 120,000$. It's possible these subsets of items are influencing the shape of the attentuation curve by confounding true $h^2_g$ with $N_{eff}$. If we restrict to variables observed in nearly all samples:

```{r n_bias_300k, echo=F}
ll <- loess(h2_liability ~ Neff, data=dat[dat$n > 300000, ], span = 1)

pp <- plot_ly(dat[dat$n > 300000, ],
              x=~Neff,
              y=~h2_liability,
              type="scatter",
              mode="markers",
              width=800,height=300,
              hoverinfo="text",
              text = ~paste0(
                "Phenotype: ", description,
                "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
                "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
                "<br>Effective N: ", Neff)) %>%
  add_trace(x=ll$x[order(ll$x)],
            y=ll$fitted[order(ll$x)],
            showlegend=F,
            mode="lines",
            hoverinfo="text",
            text="") %>%
  layout(yaxis=list(title="SNP-h^2 (liability)", range=c(-.1,.5)),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```
*Note:* zoom out for $h^2_g$ outliers.


*Takeaway:* the milder attentuation of $h^2_g$ as a function of $N_{eff}$ is still observed when restricting to `r sum(dat$n > 300000)` phenotypes with $N > 300,000$. Similar trends are observed for subsetting on other dimensions (not shown).

**Conclusion:** The mix of phenotypes doesn't appear to explain the weaker attentuation effect.

</div>

<br>

### Question 2: Attentuation evident in downsampling?

<div class="well">

Instead of looking across phenotypes, we can also consider the impact of sample size on $h^2_g$ estimates within a phenotype. We evaluate this by looking at how the LDSR estimates change when subsetting individuals from UKB for phenotypes with high $N$s and strong $h^2_g$ estimates.

Specifically, for a given downsampling experiment we split UKB individuals into 300 chunks, perform a GWAS within each chunk (controlling for the standard GWAS covariates), and then meta-analyze increasing numbers of chunks. We then run LDSR for each of these meta-analyses to assess how the $h^2_g$ estimates change with growing meta-analyses.

```{r downsample, fig.align='center', out.width=800, echo=F}
knitr::include_graphics("downsample_height.png")

knitr::include_graphics("downsample_leg.png")
```

*Note:* Above are two specific examples among a broader set of ongoing analyses. 

*Takeaway:* There are signs of attenutation of the LDSR $h^2_g$ estimate at low $N$ in height, but leg impedence shows no such attentuation, and instead may have an upward bias. In both cases, estimates are clearly unstable at low $N$.

**Conclusion:** These results are preliminary, and appear fairly unstable across phenotypes, but suggest that attenuation may occur irregularly across phenotypes and than in some instances there may be upward bias rather than downward attenuation at low sample sizes.

</div>

<br>

### Question 3: Attentuation a function of stratification?

<div class="well">

The downsampling experiments, while inconclusive, do suggest instability of the LSDR $h^2_g$ at low $N$, with variability possibly exceeding the SE estimates. Noteably, there were signs of attenuation at low $N$ for height, a phenotype where the GWAS is likely affected by population stratification (intercept = $`r signif(dat$intercept[dat$phenotype=="50_irnt"],4)`$, p = $`r signif(dat$intercept_p[dat$phenotype=="50_irnt"],3)`$, ratio = $`r signif(dat$ratio[dat$phenotype=="50_irnt"],2)`$), but not leg impedence where stratification is weaker (intercept = $`r signif(dat$intercept[dat$phenotype=="23107_irnt"],4)`$, p = $`r signif(dat$intercept_p[dat$phenotype=="23107_irnt"],3)`$, ratio = $`r signif(dat$ratio[dat$phenotype=="23107_irnt"],2)`$).

This leads us to evaluate whether the relationship between sample size and LDSR $h^2_g$ varies as a function of stratification. We start by noting that the LDSR intercept is expected to estimate $1+Na$ where $N$ is sample size and $a$ is an index of population stratification or other counfounding that is, under a simple stratification model, proportional to $F_{st}$. It follows that $a=(intercept-1)/N$ should give an estimate of stratification that is invariant to sample size. 

On that basis, we look at LDSR $h^2_g$ estimates as a function of $N_{eff}$ split by deciles of $a=(intercept-1)/N$.

```{r alpha_dec, echo=F}

dat$alpha <- (dat$intercept-1)/dat$n

pp <- plot_ly(dat,
              x=~Neff,
              y=~h2_liability,
              type="scatter",
              mode="markers",
              width=800,
              hoverinfo="text",
              text = ~paste0(
                "Phenotype: ", description,
                "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
                "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
                "<br>Effective N: ", Neff)) %>%
  layout(
    xaxis = list(title="Neff", range=c(0,200000)),
    yaxis = list(title="SNP-h^2", range=c(-.5,.5)),
    title = "alpha deciles",
    margin=list(b=65)
  )

qq <- quantile(dat$alpha,probs = seq(0,1,.1))
for(i in 1:10){
  ll <- loess(h2_liability ~ Neff, data=dat[(dat$alpha >= qq[i]) & (dat$alpha <= qq[i+1]),],span=0.5)
  pp <- pp %>% add_trace(x=ll$x[order(ll$x)],
          y=ll$fitted[order(ll$x)],
          showlegend=T,
          mode="lines",
          hoverinfo="text",
          text="",
          name=paste0("Dec",i," [",signif(qq[i],1),",",signif(qq[i+1],1),"]"))
}

htmltools::div( pp, align="center" )
rm(ll)

```

*Note:* Plot restricted to $N_{eff} < 200,000$ and $|h^2_g|<.5$ for visibility.  

From the above plot, we see a strong relationship between the trend in $h^2_g$ at low sample sizes and $a$ from the fitted intercept. These trends also continue in the sample sizes below $N_{eff}=`r req_neff_round`$ excluded above. Specifically, phenotypes at low $N_{eff}$ with higher fitted intercepts (e.g. deciles 8-10) tend to have lower $h^2_g$ estimates (to the point of the average estimate being negative), while phenotypes with lower fitted estimates (including $a < 0$, which corresponds to intercepts below 1) have higher $h^2_g$ estimates. Phenotypes with nearly null intercepts (deciles 3-4, $a \approx 0$, intercept $\approx 1$) show no directional bias on average.

It's worth noting that the trends conditional on estimated $a$ are likely to reflect both:

* Effects of true stratification/confounding in the GWAS, such that the true value of $a$ is non-zero
* Negative correlation of intercept and slope estimate from the LDSR regression when there's insufficient power to differentiate signal from noise
* Unstable trends for the top/bottom decile due to limited phenotypes with low intercept alphas at high sample size, and (to a lesser extent) with high intercepts at low sample size.

```{r neff_alpha_dist, echo=F}
pp <- plot_ly(dat, 
        y=~Neff,
        x=~cut(alpha,breaks=quantile(alpha,probs = seq(0,1,.1)),include.lowest=TRUE),
        split=~cut(alpha,breaks=quantile(alpha,probs = seq(0,1,.1)),include.lowest=TRUE),
        type='violin',
        box=list(visible=T),
        meanline=list(visible=T),
        color=~cut(alpha,breaks=quantile(alpha,probs = seq(0,1,.1)),include.lowest=TRUE),
        colors=plotly_colors[c(2:10,1)],
        height=300,width=800,
        hoveron="points",
        hoverinfo="text",
        text=~description
) %>% layout(
  yaxis = list(title="Effective N"),
  xaxis = list(title="intercept alpha decile",showticklabels=FALSE),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )
```

<br>

The stability of the $h^2_g$ estimates may also be connected to the intercept $a$ even at high sample sizes. E.g. this is evident if we focus on the top 5 deciles of $a$ in effective sample sizes above 100,000.

```{r h2_se_alpha, echo=F}
pp <- plot_ly(dat,
        x=~Neff,
        y=~h2_liability_se,
        type="scatter",
        mode="markers",
        hoverinfo="text",
        colors=plotly_colors[c(1,7:10,1)],
        height=300,width=800,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff))
  


qq <- quantile(dat$alpha,probs = seq(0,1,.1))
for(i in 6:10){
  ll <- loess(h2_liability_se ~ Neff, data=dat[(dat$alpha >= qq[i]) & (dat$alpha <= qq[i+1]),],span=0.5)
  pp <- pp %>% add_trace(x=ll$x[order(ll$x)],
          y=ll$fitted[order(ll$x)],
          showlegend=T,
          mode="lines",
          line=list(color=plotly_colors[1+(i%%10)]),
          hoverinfo="text",
          text="",
          name=paste0("Dec",i," [",signif(qq[i],1),",",signif(qq[i+1],1),"]"))
}

pp <- pp %>% layout(xaxis=list(title="Neff", range=c(100000,max(dat$Neff))),
         yaxis=list(title="SE for SNP-h^2 estimate (liability)", range=c(0,.025)),
         margin=list(b=65)
         )

htmltools::div( pp, align="center" )
```

<br>

Nevertheless, to the extent the fitted $a$ estimates don't appear centered at zero (e.g. zero is covered by decile 3, mean $a = `r signif(mean(dat$alpha),3)`$, standard deviation $= `r signif(sd(dat$alpha),3)`$) it is likely the $a$ values do reflect some non-zero amounts of confounding/stratification in at least some of the phenotypes. It is unclear however to what extent the directional biases in $h^2_g$ conditional on $a$ reflect effects from the true value of $a$ versus correlated sampling noise in the intercept and slope estimates.

The relationship to $a$ may also explain why the attenuation at low $N_{eff}$ is weaker in the Round 2 results than in Round 1. The Round 2 GWAS increased the number of PCA covariates and used PCs computed within the GWAS sample (i.e. within european ancestry individuals) rather than the PCs from the full UKB data (i.e. with all ancestries). As a result, stratification may be better controlled within the Round 2 results, thus any dependence of the $h^2_g$ results on $a$ at low $N_{eff}$ will have a weaker marginal effect than in Round 1 due to reduced true values of $a$.

*Takeaway:* In either case, it is clear from the first figure above that there is strong dependence between $h^2_g$ and $a$ at low $N_{eff}$, with convergence to more stable $h^2_g$ estimates regardless of $a$ as $N_{eff}$ increase (subject to the instability from sparse representation of the $a$ decile or increased SEs of the $h^2_g$ estimate).

</div>

### **Conclusion** 

From the plot of $h^2_g$ by $a$ decile, it appears LDSR $h^2_g$ estimates converge to stabilty in the $N_{eff}=20,000-40,000$ range. This is broadly consistent with the downsampling experiments above, though in some instances those show evidence of slightly slower convergence. Based on the above, we therefore denote our confidence in the LDSR $h^2_g$ results as follows:

* $N_{eff} < 4500$: No confidence (see [minimum sample size requirements](#minimum-sample-size-requirements))
* $4500 \leq N_{eff} < 20,000$: Low confidence
* $20,000 \leq N_{eff} < 40,000$: Medium confidence
* $N_{eff} \geq 40,000$: High confidence

[*NB:* Of the criteria in this LDSR analysis, this choice is probably the least stable. The downsampling experiments remain unclear about the nature of biases at low $N_{eff}$, suggesting effects beyond what might be anticipated based on the full-sample estimate of $a$. As a result, thoughts about best practices for interpreting $h^2_g$ estimates in this intermediate range of $N_{eff}$ are still very much subject to change.]

```{r set_neff, echo=F}

dat$isLowNeff <- F
dat$isLowNeff[dat$Neff>=4500 & dat$Neff<20000] <- T
dat$confidence[dat$isLowNeff & (dat$confidence %in% c("medium","high"))] <- "low"

dat$isMidNeff <- F
dat$isMidNeff[dat$Neff>=20000 & dat$Neff<40000] <- T
dat$confidence[dat$isMidNeff & dat$confidence=="high"] <- "medium"

dat_full$isLowNeff <- F
dat_full$isLowNeff[dat_full$Neff>=4500 & dat_full$Neff<20000] <- T
dat_full$confidence[dat_full$isLowNeff & (dat_full$confidence %in% c("medium","high"))] <- "low"

dat_full$isMidNeff <- F
dat_full$isMidNeff[dat_full$Neff>=20000 & dat_full$Neff<40000] <- T
dat_full$confidence[dat_full$isMidNeff & dat_full$confidence=="high"] <- "medium"

datm_full$isLowNeff <- F
datm_full$isLowNeff[datm_full$Neff>=4500 & datm_full$Neff<20000] <- T
datm_full$confidence[datm_full$isLowNeff & (datm_full$confidence %in% c("medium","high"))] <- "low"

datm_full$isMidNeff <- F
datm_full$isMidNeff[datm_full$Neff>=20000 & datm_full$Neff<40000] <- T
datm_full$confidence[datm_full$isMidNeff & datm_full$confidence=="high"] <- "medium"

datf_full$isLowNeff <- F
datf_full$isLowNeff[datf_full$Neff>=4500 & datf_full$Neff<20000] <- T
datf_full$confidence[datf_full$isLowNeff & (datf_full$confidence %in% c("medium","high"))] <- "low"

datf_full$isMidNeff <- F
datf_full$isMidNeff[datf_full$Neff>=20000 & datf_full$Neff<40000] <- T
datf_full$confidence[datf_full$isMidNeff & datf_full$confidence=="high"] <- "medium"



dat <- dat[dat$confidence != "low", ]
```

<br>


## Unusually large standard errors

In assessing the minimum necessary sample size [above](#minimum-sample-size-requirements), we noted the relationship between sample size and the SE of the $h^2_g$ estimate. Although we focused on the average SE by sample size, it may also be observed that there are some clear outliers with larger SEs than would be anticipated based on their sample size.

<div class="well">

We focus here on phenotypes that are at least medium confidence based on $N_{eff}$.

```{r h2_se_2, echo=F}
pp <- plot_ly(dat,
        x=~Neff,
        y=~h2_liability_se,
        type="scatter",
        mode="markers",
        color=~h2_liab,
        colors=c("blue","darkorange"),
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  layout(xaxis=list(title="Neff"),
         yaxis=list(title="SE of SNP-h^2 estimate (liability)"),
         margin=list(b=65))
htmltools::div( pp, align="center" )
```

<br>

The clearest outlier here is red hair color (from UKB code 1747). In addition to the disproportionately large SE on the $h^2_g$ estimate for this phenotype, it also has a remarkably low intercept estimate which is also unstable (intercept = `r round(dat$intercept[dat$phenotype=="1747_2"],3)`, SE = `r round(dat$intercept_se[dat$phenotype=="1747_2"],3)`). A similar pattern is observed for the next two outliers, measures of bilirubin from the biomarker data (codes 30660 and 30840). Note that an intercept $<1$ is unexpected under the LDSR model, where variants tagging no signal (LD score of 0) should have a null expectation of 1 (for the 1 df $\chi^2$ statistic).

Looking at the manhattan plot for the red hair phenotype, it becomes clear that the genetic signal is dominated by two loci. The manhattan plots for bilirubin are similarly sparse with even stronger top loci (not shown).


```{r red_hair, fig.align='center', out.width=800, echo=F}
knitr::include_graphics("1747_2_MF.png")
```

*Note:* y-axis truncated for *MC1R* locus on chromosome 16.

LDSR is derived assuming a broadly polygenic architecture for each trait. Although sparser polygenicity doesn't fully invalidate the LDSR model (under a moments-based framework), it has previously been observed that LDSR is increasingly unstable for sparse architectures. 

Although we hope that the reported SEs will accurately capture the instability of estimates for these phenotypes with sparse architectures, we may have lower confidence in these results. We may be particularly concerned about phenotypes where the SE is large and coupled with a low estimated intercept, which could in turn lead to over-estimation of $h^2_g$.

Using the same loess fit as [above](#minimum-sample-size-requirements) to predict the expected SE based on $N_{eff}$, we evaluate the ratio between the observed and expected SE along with the fitted intercept.


```{r h2_pred_se_ratio, echo=F}


pp <- plot_ly(dat,
        x=~intercept,
        y=~h2_liability_se/pred_h2liab_se,
        type="scatter",
        mode="markers",
        color=~h2_liab,
        colors=c("blue","darkorange"),
        hoverinfo="text",
        width=400,height=400,
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff)) %>%
  layout(yaxis=list(title="Observed/Predicted ratio for SNP-h^2 SE"),
         xaxis=list(title="LDSR intercept"),
         margin=list(b=65))
htmltools::div( pp, align="center" )

```

<br>

The top outliers are observed for pigmentation-related traits, which have architectures similar to red hair as illustrated above, and other biomarkers like bilirubin. Following the biomarkers, the next set of phenotypes with larger-than-expected SEs are haematology measures, such as thrombocyte volume (UKB code 30100).


```{r thrombocyte, fig.align='center', out.width=800, echo=F}
knitr::include_graphics("30100_raw_MF.png")
```

*Takeaway:* Thrombocyte volume also has loci of very strong effect, but in the context of a more polygenic architecture.

<br>

Although the unexpectedly large SEs for phenotypes like thrombocyte volume are still worrisome, they are less concerning than the stronger outliers for pigmentation-related traits and biomarkers like bilirubin whose GWAS signals are driven by only a handful of loci.

</div>

### **Conclusion** 

We mark reduced confidence in phenotypes with unexpectedly large SEs as follows:

* Low confidence: All hair color levels (UKB code 1747), plus other items with Observed/Expected SE ratios > 12 and intercepts < 1.1
* Medium confidence: All other items with Observed/Expected SE ratios > 6

All affected measures are pigmentation-related or biomarker or haemotology measures. [*NB:* Height (UKB code 50) is just barely under the 6x ratio of observed vs. expected SE. It's a borderline decision. We choose to give it some leeway given the general trend that higher $h^2_g$ also has higher SE and height has very strong $h^2_g$.]

<br>

```{r spiky_conf, echo=F}

dat$isExtremeSE <- F
dat$isExtremeSE[startsWith(dat$phenotype,"1747_") | (dat$intercept < 1.1 & (dat$h2_liability_se/dat$pred_h2liab_se) > 12)] <- T
dat$confidence[dat$isExtremeSE & (dat$confidence %in% c("medium","high"))] <- "low"

dat$isHighSE <- F
dat$isHighSE[(dat$h2_liability_se/dat$pred_h2liab_se) > 6 & !dat$isExtremeSE] <- T
dat$confidence[dat$isHighSE & dat$confidence=="high"] <- "medium"

dat_full$isExtremeSE <- F
dat_full$isExtremeSE[startsWith(dat_full$phenotype,"1747_") | (dat_full$intercept < 1.1 & (dat_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=dat_full$Neff)))) > 12)] <- T
dat_full$confidence[dat_full$isExtremeSE & (dat_full$confidence %in% c("medium","high"))] <- "low"

dat_full$isHighSE <- F
dat_full$isHighSE[(dat_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=dat_full$Neff)))) > 6 & !dat_full$isExtremeSE] <- T
dat_full$confidence[dat_full$isHighSE & dat_full$confidence=="high"] <- "medium"

datm_full$isExtremeSE <- F
datm_full$isExtremeSE[startsWith(datm_full$phenotype,"1747_") | (datm_full$intercept < 1.1 & (datm_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=datm_full$Neff)))) > 12)] <- T
datm_full$confidence[datm_full$isExtremeSE & (datm_full$confidence %in% c("medium","high"))] <- "low"

datm_full$isHighSE <- F
datm_full$isHighSE[(datm_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=datm_full$Neff)))) > 6 & !datm_full$isExtremeSE] <- T
datm_full$confidence[datm_full$isHighSE & datm_full$confidence=="high"] <- "medium"

datf_full$isExtremeSE <- F
datf_full$isExtremeSE[startsWith(datf_full$phenotype,"1747_") | (datf_full$intercept < 1.1 & (datf_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=datf_full$Neff)))) > 12)] <- T
datf_full$confidence[datf_full$isExtremeSE & (datf_full$confidence %in% c("medium","high"))] <- "low"

datf_full$isHighSE <- F
datf_full$isHighSE[(datf_full$h2_liability_se/(1/sqrt(predict(llmod, newdata=datf_full$Neff)))) > 6 & !datf_full$isExtremeSE] <- T
datf_full$confidence[datf_full$isHighSE & datf_full$confidence=="high"] <- "medium"

dat <- dat[dat$confidence != "low", ]
```

## Sex-biased phenotypes

We noted [above](#sex-specific-phenotypes) that although we were designating the both-sex analysis as the primary analysis where possible that we would revisit the question of results for phenotypes with a strong sex bias. We revisit that question here.

<div class="well">

We first look at the sex balance of phenotypes using a `both_sexes` GWAS that passed the minimum sample size filters and have high confidence after the previous checks in this section.

```{r sex_bias_conf, echo=F}

sex_ns2 <- sex_ns[sex_ns$phenotype %in% dat$phenotype[dat$sex=="both_sexes"],]
rm(sex_ns)

pp <- plot_ly(sex_ns2[!(is.na(sex_ns2$n_fem) | is.na(sex_ns2$n_mal)),],
        x=~n_fem/(n_fem+n_mal),
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Proportion of samples who are female", range=c(0,1)),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )

```

*Takeaway:* Sample sizes are nicely balanced between sexes. The small tail of items with >60% female samples primarily consists of depression-related questions.

As before, we can similarly check the balance among cases and among controls for binary phenotypes.

```{r sex_bias_cc_conf, echo=F}
pp1 <- plot_ly(sex_ns2[!(is.na(sex_ns2$n_case_fem) | is.na(sex_ns2$n_case_mal)),],
        x=~n_case_fem/(n_case_fem+n_case_mal),
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Proportion of cases who are female", range=c(0,1)),
  title = "cases",
  margin=list(b=65)
)

pp2 <- plot_ly(sex_ns2[!(is.na(sex_ns2$n_case_fem) | is.na(sex_ns2$n_case_mal)),],
        x=~n_control_fem/(n_control_fem+n_control_mal),
        type="histogram",
        showlegend=F,
        hoverinfo="none",
        width=400, height=400
        ) %>% layout(
  xaxis = list(title="Proportion of controls who are female", range=c(0,1)),
  title = "controls",
  margin=list(b=65)
)

htmltools::div(
  style = "display: flex; flex-wrap: wrap; justify-content: center",
  htmltools::div(pp1),
  htmltools::div(pp2)
)
```

Although these phenotypes are mostly balanced, there is a clear remaining tail of phenotypes with strong sex bias among cases.

We don't have particularly strong reasons to be concerned about LDSR results for phenotypes with strong sex differences. Noteably the GWAS is already conditioned on sex as a covariate (as well as $Sex \times Age$ interactions). On the other hand, we may have some concerns over whether the phenotype has the same meaning in both sexes or whether there are for example differential ascertainment biases affecting each sex in the GWAS sample. In both cases, this concern can be summarized as a worry over the potential for $G \times Sex$ interactions (either in the population or as an artifact within sample). On that basis, we choose to flag phenotypes with strong sex differences in sample size as somewhat lower confidence.

```{r apply_sex_bias, echo=F}
sex_drop1 <- sex_ns2[sex_ns2$n_fem/(sex_ns2$n_fem+sex_ns2$n_mal) > .75 |
                     sex_ns2$n_fem/(sex_ns2$n_fem+sex_ns2$n_mal) < .25 |   
                     ((sex_ns2$n_case_fem/(sex_ns2$n_case_fem+sex_ns2$n_case_mal) > .75 | 
                       sex_ns2$n_case_fem/(sex_ns2$n_case_fem+sex_ns2$n_case_mal) < .25 | 
                       sex_ns2$n_control_fem/(sex_ns2$n_control_fem+sex_ns2$n_control_mal) > .75 | 
                       sex_ns2$n_control_fem/(sex_ns2$n_control_fem+sex_ns2$n_control_mal) < .25) &
                      !is.na(sex_ns2$n_case_fem)),"phenotype"]
sex_drop1 <- sex_drop1[!is.na(sex_drop1) & (sex_drop1 %in% dat$phenotype[dat$sex=="both_sexes"])]

sex_drop2 <- onesex_ns[onesex_ns$n_sex/onesex_ns$n > 0.75 |
                        (!is.na(onesex_ns$n_case) & 
                         ((onesex_ns$n_case_sex/onesex_ns$n_case > 0.75) |
                         (onesex_ns$n_control_sex/onesex_ns$n_control > 0.75))), "phenotype"]
sex_drop2 <- sex_drop2[!is.na(sex_drop2) & (sex_drop2 %in% dat$phenotype[dat$sex=="both_sexes"])]

idx_sexconf <- (dat$phenotype %in% c(as.character(sex_drop1),as.character(sex_drop2)) & dat$sex=="both_sexes")
dat$isSexBias <- F
dat$isSexBias[idx_sexconf] <- T
dat$confidence[dat$isSexBias & dat$confidence=="high"] <- "medium"



# same checks in dat_full
# (not required in datf, datm since this is specifically a concern about both_sexes analyses)
dat_full_fem_idx <- match(dat_full$phenotype, datf_full$phenotype)
dat_full_fem_idx_na <- is.na(dat_full_fem_idx)
dat_full_fem_n <- rep(NA,nrow(dat_full))
dat_full_fem_ncase <- rep(NA,nrow(dat_full))
dat_full_fem_ncontrol <- rep(NA,nrow(dat_full))
dat_full_fem_n[!dat_full_fem_idx_na] <- datf_full$n[dat_full_fem_idx[!dat_full_fem_idx_na]]
dat_full_fem_ncase[!dat_full_fem_idx_na] <- datf_full$n_cases[dat_full_fem_idx[!dat_full_fem_idx_na]]
dat_full_fem_ncontrol[!dat_full_fem_idx_na] <- datf_full$n_controls[dat_full_fem_idx[!dat_full_fem_idx_na]]


dat_full$isSexBias <- F
dat_full$isSexBias[!is.na(dat_full_fem_n) & dat_full_fem_n/dat_full$n > .75] <- T
dat_full$isSexBias[!is.na(dat_full_fem_n) & dat_full_fem_n/dat_full$n < .25] <- T
dat_full$isSexBias[!is.na(dat_full_fem_n) & !is.na(dat_full$n_cases) & dat_full_fem_ncase/dat_full$n_cases > .75] <- T
dat_full$isSexBias[!is.na(dat_full_fem_n) & !is.na(dat_full$n_cases) & dat_full_fem_ncase/dat_full$n_cases < .25] <- T
dat_full$isSexBias[!is.na(dat_full_fem_n) & !is.na(dat_full$n_cases) & dat_full_fem_ncontrol/dat_full$n_controls > .75] <- T
dat_full$isSexBias[!is.na(dat_full_fem_n) & !is.na(dat_full$n_cases) & dat_full_fem_ncontrol/dat_full$n_controls < .25] <- T
dat_full$confidence[dat_full$isSexBias & dat_full$confidence=="high"] <- "medium"


datf_full$isSexBias <- F
datm_full$isSexBias <- F

rm(onesex_ns)
rm(sex_ns2)
```

</div>

### **Conclusion** 

We denote as "medium" confidence `r sum(idx_sexconf & !dat$isMidNeff)` phenotypes where >75% of cases are from a single sex. 

<div class="well">

```{r sexbias_list, echo=F, comment=NA}

datatable(dat[dat$isSexBias & !dat$isMidNeff,c("phenotype","description")], 
		  rownames = F, 
		  colnames = c("Code","Phenotype"), 
#		  extensions='FixedHeader', 
		  selection="none",
		  style="bootstrap", 
		  class="nowrap display", 
		  escape=F,
		  options = list(autowidth=F, scrollY="400px", scrollX='400px', pageLength=50, dom='t')#, fixedColumns=TRUE), 
)
```

<br>

[For reference, phenotypes narrowly avoiding the 3:1 threshold for reduced confidence here include: use of soy milk, taking vitamin D supplements, attending adult education classes, having gallstones, and additional headache and heart heath phenotypes.]

We only flag these phenotypes as "medium" confidence (as opposed to "low") since this is an arbitrary threshold and is only being considered out of an abundance of caution. We would also flag phenotypes with >75% of total sample size or >75% of controls from a single sex, but no such phenotypes are present here. An additional `r sum(idx_sexconf & dat$isMidNeff)` phenotypes that would meet these criteria for sex-biased prevalence are already marked as medium confidence due to limited sample size.

</div>

<br>

## Phenotypes with ordinal coding issues

In reviewing the phenotypes for this GWAS release, it was noted that the automated phenotype processing with [PHESANT](https://github.com/astheeggeggs/PHESANT) used for the GWAS yielded a small number of phenotypes with poor/uninterpretable encodings of UKB participant answers. Specifically, the issue is variables identified as ordinal by PHESANT where the labels for the ordinal levels are non-sequential numeric values and/or do not reflect that natural numeric ordering/spacing of the available response categories. For most of the identified cases this would be fine if the ordinal phenotypes were being analyzed with e.g. ordinal logistic regression as originally intended by [PHESANT](https://github.com/MRCIEU/PHESANT), but since the Neale Lab GWAS uses linear regression for all phenotypes the ordinal coding does impact the current GWAS results.

We focus here on two categories of phenotypes:

* Ordinal phenotypes whose levels are not coded as sequential integers

* Ordinal phenotypes whose integer coding does not reflect the scaling of quasi-numeric response categories

### Non-sequential ordinal coding

<div class="well">

A review of the PHESANT output for the phenotypes in the Neale lab GWAS finds 7 phenotypes with non-sequential codes. In other words, there are phenotypes that are marked as ordinal variables but don't end up with values of `[1,2,...,k]` or `[0,1,...,(k-1)]` (where $k$ is the number of response categories) in the post-PHESANT phenotypes for GWAS. The 7 identified phenotypes are: 

| Pheno. | Description | Ordinal Levels |
|-|--|--|
| [4270](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=4270) | Volume level set by participant (left) | `[10, 20, 40, 70, 100]` |
| [4277](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=4277) | Volume level set by participant (right) | `[10, 20, 40, 70, 100]` |
| [4814](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=4814) | Tinnitus severity/nuisance | `[4, 11, 12, 13]` |
| [100010](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=100010) | Portion size | `[5, 10, 15]` |
| [100400](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=100400) | Standard tea intake | `[0, 1, 2, 3, 4, 5, 600]` |
| [102290](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=102290) | Dark chocolate intake | `[0, 1, 2, 3, 4, 6]` |
| [104920](http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=104920) | Time spent doing light physical activity | `[0, 1, 13, 35, 57, 79, 912, 1200]` |

We review each of these in turn.

* 4270 and 4277 report the volume percentage selected by the participant. Although this is marked as ordinal, the response coding reflects the numerical level of the percentages. This is not problematic.

* 4814 codes reported tinnitis severity. It appears PHESANT missed recoding this variable, instead keeping the original UKB encoding of `4: Not at all`, `11: Severely`, `12: Moderately`, and `13: Slightly`. Is it evident that both the ordering and scaling of the codes is problematic.

* 100010 reflects the raw UKB encoding for portion size of `5: smaller`, `10: average`, or `15: larger` than normal portion sizes. Although a `[1,2,3]` encoding might be more conventional here, no harm is done by this alternate coding.

* 100400 codes the number of cups of tea consumed, with a code of `600` reflecting a reponse of `6+`. Obviously this coding gives dramatically outsized weight to the `6+` response in an unintended way, giving numeric weight to a placeholder value used by UKB to distinguish the `6+` response from a simple `6`. Using this value for GWAS is problematic.

* 102290 codes chocolate intake, and correctly recodes/reorders from the placeholder values reported by UKB for the number of chocolate bars consumed: `444: quarter` becomes 1, `555: half` becomes 2, `1: 1` becomes 3, `2: 2` becomes 4, `3: 3` becomes 5, `4: 4`: becomes 6, and `500: 5+` becomes 7, with a default value of 0 added for people who took the corresponding diet questionanaire but didn't report any chocolate intake. The non-sequential values occur because the the response categories for `3` and `5+` are dropped for having too few respondants. Dropping these levels may make sense for an ordinal regression, but is suboptimal for our linear regression. Giving the `quarter` and `half` response levels integer coding may also distort the phenotypic scaling in a linear regression. Thus in sum, the non-sequential codes are understandable but the encoding may still have issues; we return to this potentially error mode in the next section. 

* 104920 also appears to have missed recoding of the ordinal levels by PHESANT. The reported values conflate a range of hours spent on the activity (`0: None`, `1: Under 1 hour`, `13: 1-3 hours`, `35: 3-5 hours`, `57: 5-7 hours`, `79: 7-9 hours`, `912: 9-12 hours`, and `1200: 12+ hours`). Like the tea intake item, these are clearly placeholders and not well-suited to GWAS. The clearly nonlinear relationship between these codes and the underlying number of hours being reported is likely problematic.

*Takeaway:* Phenotypes 4814, 100400, and 104920 are clearly problematic, phenotypes 4270, 4277, and 100010 are fine with their current codings, and phenotype 104920 is concerning but not severely broken. The next section considers additional phenotypes like 104920 with potentially nonlinear encodings.

</div>

<br>

### Quasi-numeric ordinal phenotypes

<div class="well">

As is evident in the ordinal phenotypes considered above, many of the ordinal phenotypes in UK Biobank reflect response options with some degree of numeric meaning. This is evident in the case of the diet items above, where even when converted to ordinal codings as intended by PHESANT (i.e. 102290) the result is fractional values getting treated as integers and thus a nonlinearity of the numeric treatment of the phenotype. 

We therefore review the codings for all `r length(unique(dat_load[dat_load$variable_type=="ordinal", c("phenotype")]))` ordinal variables to identify phenotypes whose codings potentially reflect nonlinear codings of implied numeric values in the response categories. Three examples of phenotype codes with this kind of potential issue are shown below:

**Ever taken cannabis**

| coding | meaning |
|-|-|
| 0 | No |
| 1 | Yes, 1-2 times |
| 2 | Yes, 3-10 times |
| 3 | Yes, 11-100 times |
| 4 | Yes, more than 100 times |

**Dark chocolate intake**

| coding | meaning |
|-|-|
| 1 | quarter |
| 2 | half |
| 3 | 1 |
| 4 | 2 |
| 5 | 3 |
| 6 | 4 |
| 7 | 5+ |

**Duration of worst depression**

| coding | meaning |
|-|-|
| 1 | Less than a month |
| 2 | Between one and three months |
| 3 | Over three months, but less than six months |
| 4 | Over six months, but less than 12 months |
| 5 | One to two years |
| 6 | Over two years |

Codes are shown after the recoding done by PHESANT. The cannabis item is especially illustrative since it shows the strongly nonlinearity potentially present in the ordinal codings while simultaneously showing a scenario where that nonlinearity may be desirable (e.g. focusing on comparison of use ever vs. occassionally vs. frequently).

```{r load_ord_codes, echo=F}
# phenotypes with potentially suboptimal ordinal codes
# get based on coding, then match to phenotype number
num_codings_file <- readLines("ukb_ord_codings_warn.txt")
num_codings <- sapply(num_codings_file[grep("Code:",num_codings_file)],function(a){strsplit(a," ")[[1]][2]})

# showcase: https://github.com/astheeggeggs/PHESANT/raw/master/variable-info/Data_Dictionary_Showcase.csv
showcase <- read.delim("Data_Dictionary_Showcase.csv",header=T,stringsAsFactors=F,sep=',',quote="")
showcase <- showcase[!is.na(showcase$Coding) & showcase$Coding != "",]

num_ord <- showcase$FieldID[showcase$Coding %in% num_codings]
rm(showcase)
```


After review, we identify a total of `r length(num_codings)` response codings covering `r sum(num_ord %in% dat_load$phenotype)` phenotypes that appear at risk for this kind of nonlinear encoding of quasi-numeric response categories. A full list of the identified codings is available [here](ukb_ord_codings_warn.txt). Because the ordinal encodings of these items may bias the GWAS results compared to a GWAS of the implied numeric quantity, we designate the $h^2_g$ results for these ordinal phenotypes as "medium" confidence to reflect the impact on interpretability. 

Note the chosen list of codings is intentionally broad, and thus this reduction of confidence is likely conservative. In many cases, the coding may be close enough to linear and/or may reflect intentional choices of a scale most informative for the phenotype (e.g. the cannabis coding above), and thus the reduced confidence is unnecessary. Nevertheless, we err on the side of caution, especially since we expect the "medium" confidence results to still be included for most uses of these $h^2_g$ results, and thus use this opportunity to flag the affected ordinal phenotypes are deserving additional attention with regards to interpretation.

</div>

<br>

### **Conclusion**

```{r ord_code_probs, echo=F}

# phenotypes with hopeless ordinal codes
bad_ord <- c("4814", "100400", "104920")

dat$isBadOrdinal <- F
dat$isBadOrdinal[dat$phenotype %in% bad_ord] <- T
dat$confidence[dat$isBadOrdinal & (dat$confidence %in% c("medium","high"))] <- "low"

dat_full$isBadOrdinal <- F
dat_full$isBadOrdinal[dat_full$phenotype %in% bad_ord] <- T
dat_full$confidence[dat_full$isBadOrdinal & (dat_full$confidence %in% c("medium","high"))] <- "low"

datm_full$isBadOrdinal <- F
datm_full$isBadOrdinal[datm_full$phenotype %in% bad_ord] <- T
datm_full$confidence[datm_full$isBadOrdinal & (datm_full$confidence %in% c("medium","high"))] <- "low"

datf_full$isBadOrdinal <- F
datf_full$isBadOrdinal[datf_full$phenotype %in% bad_ord] <- T
datf_full$confidence[datf_full$isBadOrdinal & (datf_full$confidence %in% c("medium","high"))] <- "low"

dat <- dat[dat$confidence != "low", ]


# phenotypes with quasi-numeric nonlinear ordinal codes
dat$isNumericOrdinal <- F
dat$isNumericOrdinal[dat$phenotype %in% num_ord & !dat$isBadOrdinal] <- T
dat$confidence[dat$isNumericOrdinal & dat$confidence=="high"] <- "medium"

dat_full$isNumericOrdinal <- F
dat_full$isNumericOrdinal[dat_full$phenotype %in% num_ord & !dat_full$isBadOrdinal] <- T
dat_full$confidence[dat_full$isNumericOrdinal & dat_full$confidence=="high"] <- "medium"

datm_full$isNumericOrdinal <- F
datm_full$isNumericOrdinal[datm_full$phenotype %in% num_ord & !datm_full$isBadOrdinal] <- T
datm_full$confidence[datm_full$isNumericOrdinal & datm_full$confidence=="high"] <- "medium"

datf_full$isNumericOrdinal <- F
datf_full$isNumericOrdinal[datf_full$phenotype %in% num_ord & !datf_full$isBadOrdinal] <- T
datf_full$confidence[datf_full$isNumericOrdinal & datf_full$confidence=="high"] <- "medium"

```

UKB phenotypes 4814, 100400, and 104920 are marked as "low" confidence due to clear problems with the numeric values of their non-sequenital coding of ordinal response categories.

A set of `r length(num_ord)` ordinal phenotypes whose coded response levels may not fully reflect the numeric scaling of the items response categories are designated as "medium" confidence to highlight that additional follow-up may be required for interpreting their GWAS and $h^2_g$ results.

<br>

## Summary of phenotype confidence {#confidence}

In sum, the above process leaves us with:

<div class="well">

```{r conf_crosstabs, echo=F, comment=NA}
dat_all <- rbind(dat_full, datf_full, datm_full)
rm(dat_full)
rm(datf_full)
rm(datm_full)
rm(dat_load)


dat_all$notes[dat_all$notes != ""] <- paste0(dat_all$notes[dat_all$notes != ""],";")
for(flag in c("isNotPrimary","isBadPower","isLowNeff","isMidNeff","isExtremeSE","isHighSE","isSexBias","isBadOrdinal","isNumericOrdinal")){
  dat_all$notes[dat_all[,flag]] <- paste0(dat_all$notes[dat_all[,flag]],flag,";")
  dat$notes[dat[,flag]] <- paste0(dat$notes[dat[,flag]],flag,";")
}

# handle p=0
dat_all$int_p_text <- as.character(signif(dat_all$intercept_p, 3))
dat_all$int_p_text[dat_all$intercept_p==0] <- as.character(format(mpfr(0.5,64)*erfc(mpfr(dat_all$intercept_z[dat_all$intercept_p==0],64)/sqrt(mpfr(2,64))),max.digits=3,scientific=T))


# table(dat_all$notes,dat_all$confidence)
# table(dat_all$notes[!dat_all$isNotPrimary],dat_all$confidence[!dat_all$isNotPrimary])
# table(dat$notes,dat$confidence)
```

| Confidence | Count | Description |
|-|-|-----|
| NA | `r sum(dat_all$confidence=="NA_(not_primary)")` | not the primary analysis (sex-specific subset, un-normalized, redundant) |
| None | `r sum(dat_all$confidence=="none")` | $N_{eff} < 4500$ |
| Low | `r sum(dat_all$confidence=="low")` | $N_{eff} < 20000$, or $SE > 12\times$ expected with low intercept, or bad ordinal coding |
| Medium | `r sum(dat_all$confidence=="medium")` | $N_{eff} = 20000-40000$, or $SE > 6\times$ expected, or >3:1 sex bias, or nonlinear ordinal coding of numeric values |
| High | `r sum(dat_all$confidence=="high")` | remaining phenotypes |


</div>

<br>

***

# Significantly heritable phenotypes

Having established a list of phenotypes where we have reasonable confidence in the LDSR results, we can now address the question of which phenotypes are significantly heritable.

## Distribution of $h^2_g$ results

<div class="well">

As an initial observation, the distribution of $h^2_g$ results does not appear fully null within any of the confidence levels. Especially strong results are observed among the high confidence phenotypes.

```{r h2_qq, echo=F}

dat_all$conf_simple <- NA
dat_all$conf_simple[startsWith(dat_all$confidence, "none")] <- "none"
dat_all$conf_simple[startsWith(dat_all$confidence, "low")] <- "low"
dat_all$conf_simple[startsWith(dat_all$confidence, "med")] <- "medium"
dat_all$conf_simple[startsWith(dat_all$confidence, "high")] <- "high"
dat_all$conf_simple <- factor(dat_all$conf_simple, levels=c("none","low","medium","high"))


dat_all$isBinary <- !is.na(dat_all$n_cases)
dat_all$Neff <- dat_all$n
dat_all$Neff[dat_all$isBinary] <- round( (4/((1/dat_all$n_cases)+(1/dat_all$n_controls)))[dat_all$isBinary], 2)
dat_all$prevalence <- NA
dat_all$prevalence[dat_all$isBinary] <- (dat_all$n_cases/dat_all$n)[dat_all$isBinary]

qref_lo <- ppoints(sum(!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"))
qref_med <- ppoints(sum(!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"))
qref_hi <- ppoints(sum(!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"))

pp <- plot_ly(dat_all[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low",],
        y=~-log10(h2_p),
        x=~-log10(qref_lo)[rank(h2_p)],
        name="low",
        type="scatter",
        mode="markers",
        hoverinfo="text",
        text = ~paste0(
          "Phenotype: ", description,
          "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
          "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
          "<br>Effective N: ", Neff),
        width=400, height=400
        ) %>% add_markers(
          data=dat_all[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium",],
          y=~-log10(h2_p),
          x=~-log10(qref_med)[rank(h2_p)],
          name="medium",
          type="scatter",
          mode="markers",
          hoverinfo="text",
          text = ~paste0(
            "Phenotype: ", description,
            "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
            "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
            "<br>Effective N: ", Neff)
        ) %>% add_markers(
          data=dat_all[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high",],
          y=~-log10(h2_p),
          x=~-log10(qref_hi)[rank(h2_p)],
          name="high",
          type="scatter",
          mode="markers",
          hoverinfo="text",
          text = ~paste0(
            "Phenotype: ", description,
            "<br>Intercept: ", round(intercept,5), " (p=",int_p_text,")",
            "<br>Liability SNP-h^2: ", round(h2_liability,4), " (p=",signif(h2_p, 3),")",
            "<br>Effective N: ", Neff)
        ) %>% add_trace(
          x=-log10(qref_lo),
          y=-log10(qref_lo),
          showlegend=F,
          type="scatter",
          mode="lines",
          hoverinfo="text",
          text=""
        ) %>% layout(
          xaxis = list(title="Expected -log10(p)"),
          yaxis = list(title="-log10(p) for SNP-h^2"),
          margin=list(b=65)
        )
htmltools::div( pp, align="center" )
```

*Note:* Expected quantiles are computed within each confidence bin.

Weaker p-values among the lower confidence phenotypes are not surprising given that most phenotypes in those bins have reduced confidence due to smaller sample sizes. This is especially true for the phenotypes designated as "medium" confidence due to potential sex biases or nonlinear ordinal codings, where the potential biases are unlikely to completely remove true signal from their GWAS. Conversely, it is not surprising that there are non-significant results among the high confidence phenotypes since the confidence level is not assigned based on the $h^2_g$ estimate, only based on expectations about the stability and potential biases in that estimate.

```{r h2_dist, echo=F}
pp <- plot_ly(dat_all[!is.na(dat_all$conf_simple) & dat_all$conf_simple!="none",], 
        y=~h2_liability,
        x=~conf_simple,
        split=~conf_simple,
        type='violin',
        box=list(visible=T),
        meanline=list(visible=T),
        width=800,
        hoveron="points",
        hoverinfo="text",
        text=~description
) %>% layout(
  xaxis = list(title="confidence"),
  yaxis = list(title="SNP-h^2 (liability)", range=c(-.2,.7)),
  margin=list(b=65)
)
htmltools::div( pp, align="center" )
```
*Note:* Range resticted for visibility. Zoom out to see additional low confidence results above and below the plotted region.

Noteably, the distribution of $h^2_g$ point estimates is similar across the confidence levels, albeit nosier in the low confidence set. 

</div>

<br>

## Multiple testing correction

Given the large number of phenotypes, it's important to account for multiple testing in defining significance for the $h^2_g$ estimates. Although we might be comfortable with a conventional Bonferroni correction for significance, this is complicated by two considerations:

* Should we test low confidence results? (i.e. should phenotypes denoted as low confidence count towards the number of tests to be corrected for in the Bonferroni adjustment)
* How should we address correlation between the phenotypes? We know many of the UK Bioank phenotypes are strongly correlated, and the Bonferroni significance threshold will be very conservative if we treat the test of those phenotypes as independent.

<br> 

### Estimating the effective number of independent tests

<div class="well">

Focusing on the question of *independent* tests, we can adopt the method of [Li et al. 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059433/) to estimate the number of effectively independent phenotypes ($M_{eff}$) based on the observed correlation between the phenotypes. Specifically, we compute $M_{eff} = M - \sum I(\lambda_i > 1)(\lambda_i-1)$ where $\lambda_i$ are the eigenvalues of the phenotypic correlation matrix. Thus asymptotically $M_{eff}=M$ when the phenotypes are independent (i.e. all $lambda_i=1$) and shrinks proportional to the amount of redundancy from correlation between phenotypes.


```{r build_corrmat, echo=F}
# initialize matrix
rrmat <- as.data.frame(matrix(NA,sum(!dat_all$isNotPrimary & !dat_all$confidence=="none"),sum(!dat_all$isNotPrimary & !dat_all$confidence=="none")))
rownames(rrmat) <- dat_all$phenotype[!dat_all$isNotPrimary & !dat_all$confidence=="none"]
colnames(rrmat) <- paste0("phen_",rownames(rrmat))

# prep list of phenotypes by sex used as primary
both_nam <- dat_all$phenotype[dat_all$sex=="both_sexes" & !dat_all$isNotPrimary & !dat_all$confidence=="none"]
fem_nam <- dat_all$phenotype[dat_all$sex=="female" & !dat_all$isNotPrimary & !dat_all$confidence=="none"]
mal_nam <- dat_all$phenotype[dat_all$sex=="male" & !dat_all$isNotPrimary & !dat_all$confidence=="none"]


# XXX TEMP FIX #
both_nam <- dat_all$phenotype[dat_all$sex=="both_sexes" & !dat_all$isNotPrimary & !dat_all$confidence=="none" & !dat_all$source=="biomarkers"]
fem_nam <- dat_all$phenotype[dat_all$sex=="female" & !dat_all$isNotPrimary & !dat_all$confidence=="none" & !dat_all$source=="biomarkers"]
mal_nam <- dat_all$phenotype[dat_all$sex=="male" & !dat_all$isNotPrimary & !dat_all$confidence=="none" & !dat_all$source=="biomarkers"]


# start with both_sexes gwas
# rrmat_both <- read.table("bothsexes_resid_corrmat.csv",header=T,row.names=1,stringsAsFactors=F,sep=',')
# rownames(rrmat_both)[rownames(rrmat_both)=="isFemale"] <- "is_female"
# colnames(rrmat_both) <- paste0("phen_",rownames(rrmat_both))
rrmat[both_nam,paste0("phen_",both_nam)] <- rrmat_both[match(both_nam,rownames(rrmat_both)), match(both_nam,rownames(rrmat_both))]
rm(rrmat_both)

# load and add female gwas
rrmat_fem <- read.table("females_resid_corrmat.csv",header=T,row.names=1,stringsAsFactors=F,sep=',')
colnames(rrmat_fem) <- paste0("phen_",rownames(rrmat_fem))
rrmat[fem_nam,paste0("phen_",fem_nam)] <- rrmat_fem[match(fem_nam,rownames(rrmat_fem)), match(fem_nam,rownames(rrmat_fem))]
rrmat[fem_nam,paste0("phen_",both_nam[both_nam %in% rownames(rrmat_fem)])] <- rrmat_fem[match(fem_nam,rownames(rrmat_fem)), match(both_nam[both_nam %in% rownames(rrmat_fem)],rownames(rrmat_fem))]
rrmat[both_nam[both_nam %in% rownames(rrmat_fem)],paste0("phen_",fem_nam)] <- rrmat_fem[match(both_nam[both_nam %in% rownames(rrmat_fem)],rownames(rrmat_fem)), match(fem_nam,rownames(rrmat_fem))]
rm(rrmat_fem)

# load and add male gwas
rrmat_mal <- read.table("males_resid_corrmat.csv",header=T,row.names=1,stringsAsFactors=F,sep=',')
colnames(rrmat_mal) <- paste0("phen_",rownames(rrmat_mal))
rrmat[mal_nam,paste0("phen_",mal_nam)] <- rrmat_mal[match(mal_nam,rownames(rrmat_mal)), match(mal_nam,rownames(rrmat_mal))]
rrmat[mal_nam,paste0("phen_",both_nam[both_nam %in% rownames(rrmat_mal)])] <- rrmat_mal[match(mal_nam,rownames(rrmat_mal)), match(both_nam[both_nam %in% rownames(rrmat_mal)],rownames(rrmat_mal))]
rrmat[both_nam[both_nam %in% rownames(rrmat_mal)],paste0("phen_",mal_nam)] <- rrmat_mal[match(both_nam[both_nam %in% rownames(rrmat_mal)],rownames(rrmat_mal)), match(mal_nam,rownames(rrmat_mal))]
rm(rrmat_mal)

# zero NAs
rrmat[is.na(rrmat)] <- 0

###

# load Ns

# initialize matrix
nnmat <- as.data.frame(matrix(NA,sum(!dat_all$isNotPrimary & !dat_all$confidence=="none"),sum(!dat_all$isNotPrimary & !dat_all$confidence=="none")))
rownames(nnmat) <- dat_all$phenotype[!dat_all$isNotPrimary & !dat_all$confidence=="none"]
colnames(nnmat) <- paste0("phen_",rownames(rrmat))

# start with both_sexes gwas
# nnmat_both <- read.table("bothsexes_pairwise_complete_ns.csv",header=T,sep=',',stringsAsFactors=F,row.names=1)
rownames(nnmat_both)[rownames(nnmat_both)=="isFemale"] <- "is_female"
colnames(nnmat_both) <- paste0("phen_",rownames(nnmat_both))
nnmat[both_nam,paste0("phen_",both_nam)] <- nnmat_both[match(both_nam,rownames(nnmat_both)), match(both_nam,rownames(nnmat_both))]
rm(nnmat_both)

# load and add female gwas
nnmat_fem <- read.table("females_pairwise_complete_ns.csv",header=T,sep=',',stringsAsFactors=F,row.names=1)
colnames(nnmat_fem) <- paste0("phen_",rownames(nnmat_fem))
nnmat[fem_nam,paste0("phen_",fem_nam)] <- nnmat_fem[match(fem_nam,rownames(nnmat_fem)), match(fem_nam,rownames(nnmat_fem))]
nnmat[fem_nam,paste0("phen_",both_nam[both_nam %in% rownames(nnmat_fem)])] <- nnmat_fem[match(fem_nam,rownames(nnmat_fem)), match(both_nam[both_nam %in% rownames(nnmat_fem)],rownames(nnmat_fem))]
nnmat[both_nam[both_nam %in% rownames(nnmat_fem)],paste0("phen_",fem_nam)] <- nnmat_fem[match(both_nam[both_nam %in% rownames(nnmat_fem)],rownames(nnmat_fem)), match(fem_nam,rownames(nnmat_fem))]
rm(nnmat_fem)

# load and add male gwas
nnmat_mal <- read.table("males_pairwise_complete_ns.csv",header=T,sep=',',stringsAsFactors=F,row.names=1)
colnames(nnmat_mal) <- paste0("phen_",rownames(nnmat_mal))
nnmat[mal_nam,paste0("phen_",mal_nam)] <- nnmat_mal[match(mal_nam,rownames(nnmat_mal)), match(mal_nam,rownames(nnmat_mal))]
nnmat[mal_nam,paste0("phen_",both_nam[both_nam %in% rownames(nnmat_mal)])] <- nnmat_mal[match(mal_nam,rownames(nnmat_mal)), match(both_nam[both_nam %in% rownames(nnmat_mal)],rownames(nnmat_mal))]
nnmat[both_nam[both_nam %in% rownames(nnmat_mal)],paste0("phen_",mal_nam)] <- nnmat_mal[match(both_nam[both_nam %in% rownames(nnmat_mal)],rownames(nnmat_mal)), match(mal_nam,rownames(nnmat_mal))]
rm(nnmat_mal)

diag(nnmat) <- 1000000
n_lim <- 1000
rrmat[nnmat < n_lim] <- 0

```

We estimate these phenotypic correlations from the UK Biobank GWAS sample (minus a handful of individuals who have withdrawn since the Round 2 GWAS release) after residualizing on the GWAS covariates ($sex, age, age^2, sex \times age, sex \times age^2, 20 PCs$) using pairwise complete data. This leaves some phenotypic correlations that either cannot be estimated due to never being measured in the same individual (e.g. sex-specific items across sex, or other conditional dependencies on previous items), or where the correlation estimate is highly unstable due to the number of intersecting individuals observed for both phenotypes is small. To resolve this, we conversatively set to zero all correlations between pairs of phenotypes where less than `r n_lim` individuals are observed for both phenotypes.

```{r effect_tests, echo=F}
ntest_high <- sum(dat_all$conf_simple=="high", na.rm = T)
ntest_medhigh <- sum(dat_all$conf_simple %in% c("medium","high"), na.rm = T)
ntest_lmedhigh <- sum(dat_all$conf_simple %in% c("low","medium","high"), na.rm = T)

# get eigenvalues
eval_l <- eigen(rrmat[rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("low","medium","high")],
                      rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("low","medium","high")]])$values
eval_m <- eigen(rrmat[rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("medium","high")],
                      rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("medium","high")]])$values
eval_h <- eigen(rrmat[rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("high")],
                      rownames(rrmat) %in% dat_all$phenotype[dat_all$conf_simple %in% c("high")]])$values

# compute effective tests
# Method of Li et al, 2011, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059433/
meff_low <- ntest_lmedhigh - sum(eval_l[eval_l>1]-1)
meff <- ntest_medhigh - sum(eval_m[eval_m>1]-1)
meff_high <- ntest_high - sum(eval_h[eval_h>1]-1)

# c(meff_low,meff,meff_high) for N thresholds c(0,10,100,1000,10000) on correlation matrix excluding biomarkers
# we end up using N=1000 here
# [1] 1137.62  689.56  466.31
# [1] 1161.36  709.71  477.98
# [1] 1163.21  710.34  477.98
# [1] 1166.77  710.73  477.98
# [1] 1188.47  710.36  477.92

rm(rrmat)
rm(nnmat)
```

This computation of $M_{eff}$ suggests:

* `r round(meff_high,2)` tests among high confidence phenotypes alone
* `r round(meff,2)` tests among medium and high confidence phenotypes combined
* `r round(meff_low,2)` tests among low, medium, and high confidence phenotypes combined

We skip computation of $M_{eff}$ including phenotypes with no confidence since we generally don't recommend use of those results.

</div>

<br>

## **Conclusion:** significance thresholds {#sig_thresh}

<div class="well">

The above process leaves us with a large number of possible p-value thresholds:

* $p<.05$ for nominal significance
* $p<`r signif(.05/meff_high,3)`$ for the `r round(meff_high,2)` effective tests in high confidence phenotypes
* $p<`r signif(.05/ntest_high,3)`$ for the `r ntest_high` high confidence phenotypes, treating them as independent
* $p<`r signif(.05/meff,3)`$ for the `r round(meff,2)` effective tests in medium and high confidence phenotypes 
* $p<`r signif(.05/ntest_medhigh,3)`$ for the `r ntest_medhigh` medium and high confidence phenotypes, treating them as independent
* $p<`r signif(.05/meff_low,3)`$ for the `r round(meff_low,2)` effective tests in low, medium and high confidence phenotypes
* $p<`r signif(.05/ntest_lmedhigh,3)`$ for the `r ntest_lmedhigh` low, medium, and high confidence phenotypes, treating them as independent
* $p<`r signif(.05/sum(!dat_all$isNotPrimary),3)`$ for the `r sum(!dat_all$isNotPrimary)` GWASed phenotypes(including those with no confidence for `ldsc`), treating them as independent
* $p < 3.167 \times 10^{-5}\ (z > 4)$ as previously suggested as a rule of thumb for the necessary level of $h^2_g$ signal necessary to support subsequent LDSR analyses of genetic correlation ($r_g$; [Bulik-Sullivan et al. 2015](https://www.ncbi.nlm.nih.gov/pubmed/26414676)) 
* $p < 1.280 \times 10^{-12}\ (z > 7)$ as previously suggested as a threshold for inclusion in stratified LDSR analyses ([Finucane et al. 2015](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4626285/))

We observe that the differences between most of these options based on (effective) number of tests is fairly marginal. Splitting the phenotypes by confidence level, we see the number of phenotypes surpassing each p-value threshold is quite similar.

| Threshold | Low Conf. | Medium Conf. | High Conf. |
|-|-|-|------|
| $p<`r signif(.05/meff_high,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/meff_high)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/meff_high)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/meff_high)` |
| $p<`r signif(.05/ntest_high,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/ntest_high)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/ntest_high)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/ntest_high)` |
| $p<`r signif(.05/meff,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/meff)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/meff)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/meff)` |
| $p<`r signif(.05/ntest_medhigh,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/ntest_medhigh)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/ntest_medhigh)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/ntest_medhigh)` |
| $p<`r signif(.05/meff_low,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/meff_low)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/meff_low)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/meff_low)` |
| $p<`r signif(.05/ntest_lmedhigh,3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/ntest_lmedhigh)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/ntest_lmedhigh)` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/ntest_lmedhigh)` |
| $p<`r signif(.05/sum(!dat_all$isNotPrimary),3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < .05/sum(!dat_all$isNotPrimary))` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < .05/sum(!dat_all$isNotPrimary))` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < .05/sum(!dat_all$isNotPrimary))` |
| $p < `r signif(pnorm(4,lower=F),3)`$ | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="low"] < pnorm(4,lower=F))` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="medium"] < pnorm(4,lower=F))` | `r sum(dat_all$h2_p[!dat_all$isNotPrimary & dat_all$confidence=="high"] < pnorm(4,lower=F))` |

For simplicity, we choose to focus on reporting the following levels:

| Level | Criteria | Description |
|-|--|-----|
| NA | low confidence | not evaluated due to risk of biases/instability |
| NonSig | $p > .05$ | insufficient evidence for $h^2_g > 0$ |
| Nominal | $p < .05$ | if you only looked at one phenotype... |
| z4 | $p < 3.17 \times 10^{-5}\ (z > 4)$ | Bonferroni sig. for medium/high confidence phenotypes, sufficient for $r_g$ analysis |
| z7 | $p < 1.28 \times 10^{-12}\ (z > 7)$ | significant enough for stratified LDSR |

We anticipate that these should cover most of the range of interests in using and interpreting the LDSR $h^2_g$ results. we adopt $z > 4$ as the primary significance threshold, since it conservatively approximates the Bonferroni thresholds of interest (among medium and high confidence phenotypes) and matches the previously suggested standard for recommending followup analyses. This conservative choice does mean that a few phenotypes that would reach significance under one of the other thresholds are omitted, but p-values and results for all phenotypes are reported so other thresholds can be applied by other researchers if desired.

</div>

### Summary

<div class="well">

The resulting breakdown of phenotypes with significant heritability is:

```{r h2_sig, echo=F}

dat_all$h2_sig <- NA
dat_all$h2_sig[!is.na(dat_all$conf_simple) & 
                 (dat_all$conf_simple %in% c("medium","high")) &
                 dat_all$h2_p >= .05] <- "nonsig"
dat_all$h2_sig[!is.na(dat_all$conf_simple) & 
                 (dat_all$conf_simple %in% c("medium","high")) &
                 dat_all$h2_p < .05] <- "nominal"
dat_all$h2_sig[!is.na(dat_all$conf_simple) & 
                 (dat_all$conf_simple %in% c("medium","high")) &
                 dat_all$h2_z > 4] <- "z4"
dat_all$h2_sig[!is.na(dat_all$conf_simple) & 
                 (dat_all$conf_simple %in% c("medium","high")) &
                 dat_all$h2_z > 7] <- "z7"
dat_all$h2_sig <- factor(dat_all$h2_sig, levels=c("nonsig","nominal","z4","z7"))

# table(dat_all$conf_simple[!is.na(dat_all$conf_simple)], dat_all$h2_sig[!is.na(dat_all$conf_simple)], useNA="ifany")

```

| Confidence | NonSig | Nominal | z4 | z7 | NA |
|--|-|-|-|-|-|
| low | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"]=="nonsig",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"]=="nominal",na.rm=T)` | `r  sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"]=="z4",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"]=="z7",na.rm=T)` | `r sum(is.na(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="low"]),na.rm=T)` |
| medium | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"]=="nonsig",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"]=="nominal",na.rm=T)` | `r  sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"]=="z4",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"]=="z7",na.rm=T)` | `r sum(is.na(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="medium"]),na.rm=T)` |
| high | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]=="nonsig",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]=="nominal",na.rm=T)` | `r  sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]=="z4",na.rm=T)` | `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]=="z7",na.rm=T)` | `r sum(is.na(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]),na.rm=T)` |


Totalling `r sum(as.character(dat_all$h2_sig[!is.na(dat_all$conf_simple) & (dat_all$conf_simple %in% c("medium","high"))]) %in% c("z4","z7"),na.rm=T)` significant phenotypes ($z > 4$ with medium or high confidence), with `r sum(dat_all$h2_sig[!is.na(dat_all$conf_simple) & dat_all$conf_simple=="high"]=="z7",na.rm=T)` highest tier results ($z > 7$ with high confidence).
</div>

<br>

```{r save_results, echo=F, warnings=F, message=F}

# fix p=0
for(jj in grep("_p$",names(dat_all))){
  if(any(!is.na(dat_all[,jj]) & dat_all[,jj]==0)){
    jjz <- grep(gsub("_p$","_z",names(dat_all)[jj]),names(dat_all))
    # print(paste("replacing p=0 in",names(dat_all)[jj],"using z score",names(dat_all)[jjz],sep=" "))
    zero_p <- which(!is.na(dat_all[,jj]) & dat_all[,jj]==0)
    dat_all[zero_p,jj] <- format(mpfr(0.5,64)*erfc(mpfr(dat_all[[jjz]][zero_p],64)/sqrt(mpfr(2,64))), max.digits=15, scientific=T)
    }
}

dat_all <- dat_all[,-which(names(dat_all)=="int_p_text")]

out1 <- dat_all[!is.na(dat_all$conf_simple),c("phenotype","description","h2_liability","h2_liability_se","h2_observed","h2_observed_se","h2_z","h2_p","h2_sig","confidence","notes","intercept","intercept_se","intercept_z","intercept_p","lambdaGC","mean_chi2","ratio","ratio_se","n","Neff","variable_type","isBinary","n_cases","n_controls","prevalence","source","sex","isNotPrimary","isBadPower","isLowNeff","isMidNeff","isExtremeSE","isHighSE","isSexBias","isBadOrdinal","isNumericOrdinal")]

out2 <- dat_all[(dat_all$conf_simple=="medium" | dat_all$conf_simple=="high") & as.character(dat_all$h2_sig) %in% c("z4","z7"),]

# h2 only
con1 <- gzfile("ukb31063_h2_topline.13aug2019.tsv.gz","w")
write.table(out1,file=con1,sep='\t',col.names=T,row.names=F,quote=F)
close(con1)

# sig heritable
con2 <- gzfile("ukb31063_h2_z4.13aug2019.tsv.gz","w")
write.table(out2,file=con2,sep='\t',col.names=T,row.names=F,quote=F)
close(con2)

# all with annotations
con3 <- gzfile("ukb31063_h2_all.13aug2019.tsv.gz","w")
write.table(dat_all,file=con3,sep='\t',col.names=T,row.names=F,quote=F)
close(con3)
```

***

# Credits

<div class="well">

* **Primary analysis:** Raymond Walters (any and all mistakes above are mine)
* **LDSR analysis support:** Nikolas Baya, Katherine Tashman, Danfeng Chen, Liam Abbott
* **LDSR downsampling results:** Nikolas Baya
* **Manhattan plots:** Andrea Ganna (and check out [GWASbot](http://twitter.com/SbotGwa))
* **Phenotype analysis support**: Caitlin Carey, Duncan Palmer
* **Supervision**: Benjamin Neale
* **UK Biobank GWAS Core Team:** Liam Abbott, Sam Bryant, Claire Churchhouse, Andrea Ganna, Daniel Howrigan, Duncan Palmer, Ben Neale, Raymond Walters, Caitlin Carey, The Hail team
* **UK Biobank GWAS Contributors:** Verneri Anttila, Krishna Aragam, Alex Baumann, Joanne Cole, Mark J. Daly, Rob Damian, Mary Haas, Joel Hirschhorn, Eric Jones, Ruchi Munshi, Manuel Rivas, Sailaja Vedantam

With additional thanks to Alex Bloemendal, Patrick Turley, Robert Maier, Michel Nivard, Steven Gazal, Tarjinder Singh, and many others for helpful conversations.

</div>

***


